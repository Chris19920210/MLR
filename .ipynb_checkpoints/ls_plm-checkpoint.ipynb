{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import copy\n",
    "from __future__ import division\n",
    "import traceback\n",
    "\n",
    "# with dense vector negative sample 0, postive sample 1\n",
    "def performance(f):\n",
    "    def fn(*args, **kw):\n",
    "        t_start = time.time()\n",
    "        r = f(*args, **kw)\n",
    "        t_end = time.time()\n",
    "        print ('call %s() in %fs' % (f.__name__, (t_end - t_start)))\n",
    "        return r\n",
    "    return fn\n",
    "\n",
    "\n",
    "# U is 2d-array with 2m*d dimension for each person item tuple of (x, label)\n",
    "\n",
    "def mlr(W, U, x):\n",
    "    \"\"\"\n",
    "    calculate mixture logistic regression\n",
    "    :param U: m * d\n",
    "    :param W: m * d\n",
    "    :param x: d\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    ux = np.dot(U, x)\n",
    "    eux = softmax(ux)\n",
    "    del ux\n",
    "    return np.dot(eux, sigmoid(np.dot(W, x)))\n",
    "\n",
    "def sigmoid(z):\n",
    "    \"\"\"\n",
    "    calculate sigmoid\n",
    "    :param z:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def softmax(x):\n",
    "    \"\"\"\n",
    "    softmax a array\n",
    "    :param x:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    e_x = np.exp(x)\n",
    "    return e_x / e_x.sum()\n",
    "\n",
    "def calLoss(X, y, weight_W, weight_U, norm21, norm1):\n",
    "    \"\"\"\n",
    "    :param data:\n",
    "    :param weight_W:\n",
    "    :param weight_U:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    functionLoss = calFunctionLoss(weight_W, weight_U, X, y)\n",
    "    norm21Loss = calNorm21(weight_W + weight_U)\n",
    "    norm1Loss = calNorm1(weight_W + weight_U)\n",
    "    print(functionLoss , norm21 * norm21Loss , norm1 * norm1Loss)\n",
    "    return functionLoss + norm21 * norm21Loss + norm1 * norm1Loss\n",
    "\n",
    "def calFunctionLossOne(W_w, W_u,x, y):\n",
    "    p = mlr(W_w, W_u, x)\n",
    "    if y == 0:\n",
    "        return - np.log(1 - p)\n",
    "    else:\n",
    "        return - np.log(p)\n",
    "\n",
    "\n",
    "def calFunctionLoss(W_w, W_u, X, y):\n",
    "    \"\"\"\n",
    "    calculate the loss over all data\n",
    "    :param w_w:\n",
    "    :param w_u:\n",
    "    :param data:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    loss = map(lambda (x,y): calFunctionLossOne(W_w,W_u,x, y), zip(X, y))\n",
    "    loss = sum(loss)\n",
    "    return loss\n",
    "    # print(\"loss is:  %s\" % loss)\n",
    "\n",
    "def calNorm21(weight):\n",
    "    '''\n",
    "        计算norm21\n",
    "    :param weight:\n",
    "    :return:\n",
    "    '''\n",
    "    return (weight ** 2).sum() ** 0.5\n",
    "\n",
    "def calNorm1(weight):\n",
    "    \"\"\"\n",
    "        计算norm1\n",
    "    :param weight:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    return np.abs(weight).sum()\n",
    "\n",
    "def calDimension21(W):\n",
    "    \"\"\"\n",
    "        计算每一个维度的L2\n",
    "    :param W:\n",
    "    :return:{dimension1:std1, dimension2:std2 ......}\n",
    "    \"\"\"\n",
    "    return (W**2).sum(axis = 0) ** 0.5\n",
    "\n",
    "# derivative for each sample\n",
    "def cal_derivative(W_w, W_u, x, y):\n",
    "    \"\"\"\n",
    "    calculate derivative\n",
    "    :param weight:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    ux = np.dot(W_u, x)\n",
    "    eux = softmax(ux)\n",
    "    del ux\n",
    "    sig = sigmoid(np.dot(W_w, x))\n",
    "    mlr = np.dot(eux, sig)\n",
    "    prob_scalar =  - (y - mlr) / (mlr * (1 - mlr))\n",
    "    dir_U = np.outer(prob_scalar * eux * (sig - mlr), x)\n",
    "    dir_W = np.outer(prob_scalar * sig * (1 - sig) * eux, x)\n",
    "    return dir_W, dir_U\n",
    "\n",
    "\n",
    "def sumCalDerivative(WW, WU, X, y):\n",
    "    all = map(lambda (x,y): cal_derivative(WW, WU,x, y), zip(X,y))\n",
    "    LW, LU = reduce(lambda x, y: (x[0] + y[0], x[1] + y[1]),all,(0,0))\n",
    "    return LW, LU\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def virtualGradient(WW, WU, GW, GU,beta,lamb):\n",
    "    \"\"\"\n",
    "    :param weight_W:\n",
    "    :param weight_U:\n",
    "    :param gradient_W:\n",
    "    :param gradient_U:\n",
    "    :param norm21:\n",
    "    :param norm1:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    #计算θ_i·\n",
    "    D21 = calDimension21(WW + WU)\n",
    "    #计算v：\n",
    "    VW = calV(GW, beta)\n",
    "    VU = calV(GU, beta)\n",
    "    #计算v_i·\n",
    "    VD21 = calDimension21(VW + VU)\n",
    "    sumVD21 = sum(VD21)\n",
    "    #计算d_ij\n",
    "    DW = calDij(GW, WW, VW, D21, sumVD21, beta, lamb)\n",
    "    DU = calDij(GU, WU, VU, D21, sumVD21, beta, lamb)\n",
    "    return DW, DU\n",
    "\n",
    "\n",
    "def calV(L, beta):\n",
    "    \"\"\"\n",
    "    :param LW:\n",
    "    :param LU:\n",
    "    :param beta:\n",
    "    :param lamb:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    V = np.copy(L)\n",
    "    V = np.maximum(np.abs(V) - beta, 0)\n",
    "    return V*np.sign(-L)\n",
    "\n",
    "def calDij(L, W, V, D21, sumVD21, beta, lamb):\n",
    "    mask1 = (W != 0)\n",
    "    mask2 = (W == 0) * np.tile((D21 != 0), (len(W),1))\n",
    "    mask3 = np.tile((D21 == 0), (len(W),1))\n",
    "    D21_tmp = np.copy(D21)\n",
    "    D21_tmp[D21_tmp == 0] = 1\n",
    "    s = - L - lamb * W / D21_tmp\n",
    "    cond1 =  s - beta * np.sign(W)\n",
    "    cond2 = np.maximum(np.abs(s) - beta, 0.0)*np.sign(s)\n",
    "    if (sumVD21 != 0 ):\n",
    "        cond3 = V * (max(sumVD21 - lamb, 0.0) / sumVD21)\n",
    "    else:\n",
    "        cond3 = V * max(sumVD21 - lamb, 0.0)\n",
    "    return mask1 * cond1 + mask2 * cond2 + mask3 * cond3\n",
    "\n",
    "\n",
    "def loop(length, latest, direction):\n",
    "    count = 0\n",
    "    if(direction == 'right'):\n",
    "        while(count < length):\n",
    "            if(latest + count + 1 < length):\n",
    "                yield latest + count + 1\n",
    "                count += 1\n",
    "            else:\n",
    "                yield latest + count + 1 - length\n",
    "                count += 1\n",
    "    elif(direction == 'left'):\n",
    "        while(count < length):\n",
    "            if(latest - count >= 0):\n",
    "                yield latest - count\n",
    "                count += 1\n",
    "            else:\n",
    "                yield length + latest - count\n",
    "                count += 1\n",
    "    else:\n",
    "        raise Exception(\"please enter left or right\")\n",
    "\n",
    "\n",
    "def adam(VW, VU,m_w, m_u, v_w, v_u, beta1, beta2, it, alpha, epison):\n",
    "    m_w = beta1 * m_w - (1 - beta1) * VW\n",
    "    m_u = beta1 * m_u - (1 - beta1) * VU\n",
    "    v_w = beta2 * v_w + (1 - beta2) * (VW**2)\n",
    "    v_u = beta2 * v_u + (1 - beta2) * (VU**2)\n",
    "    m_w_hat = -m_w / (1 - beta1 ** it)\n",
    "    m_u_hat = -m_u / (1 - beta1 ** it)\n",
    "    mask_w = np.sign(m_w_hat) * np.sign(VW) > 0\n",
    "    mask_u = np.sign(m_u_hat) * np.sign(VU) > 0\n",
    "    m_w_hat = m_w_hat * mask_w\n",
    "    m_u_hat = m_u_hat * mask_u\n",
    "    v_w_hat = v_w / (1 - beta2**it)\n",
    "    v_u_hat = v_u / (1 - beta2**it)\n",
    "    return m_w, m_u, v_w, v_u, alpha * (m_w_hat / (v_w_hat ** 0.5 + epison)), alpha * (m_u_hat / (v_u_hat  ** 0.5 + epison))\n",
    "\n",
    "\n",
    "## weight_w, weight_u, s\n",
    "def lbfgs(VW, VU, sList_w,sList_u, yList_w, yList_u, k, m, start):\n",
    "    \"\"\"\n",
    "    :param feaNum:\n",
    "    :param gk : matrix, 2m*d\n",
    "    :param sList:3d*matrix,steps * 2m * d\n",
    "    :param yList:3d*matrix, steps * 2m * d\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if((sList_w[start] * yList_w[start] + sList_u[start] * yList_u[start]).sum() > 0 ):\n",
    "        q_u = np.copy(VU)\n",
    "        q_w = np.copy(VW)\n",
    "        # for delta\n",
    "        L = k + 1 if k < m else m\n",
    "        alphaList = np.zeros(L)\n",
    "        ro = (yList_w[(start - 1) % m] * sList_w[(start - 1) % m] + yList_u[(start - 1) % m] * sList_u[(start - 1) % m]).sum()\n",
    "        print (\"ro %f\" % ro)\n",
    "\n",
    "        for i in loop(L, start, 'left'):\n",
    "            alpha = (sList_u[i] * q_u + sList_w[i] * q_w).sum() / (sList_u[i] * yList_u[i] + sList_w[i] * yList_u[i]).sum()\n",
    "            print (\"alpha %f\" % alpha)\n",
    "            if(alpha == np.nan or alpha == np.inf or alpha == -np.inf):\n",
    "                return VW, VU\n",
    "            q_u = q_u - alpha * yList_u[i]\n",
    "            q_w = q_w - alpha * yList_w[i]\n",
    "            alphaList[i] = alpha\n",
    "        \n",
    "        q_u = q_u * ro\n",
    "        q_w = q_w * ro\n",
    "\n",
    "        for i in loop(L,start,'right'):\n",
    "            beta = (yList_u[i] * q_u + yList_w[i] * q_w).sum() / (sList_u[i] * yList_u[i] + sList_w[i] * yList_u[i]).sum()\n",
    "            q_u = q_u + (alphaList[i] - beta) * sList_u[i]\n",
    "            q_w = q_w + (alphaList[i] - beta) * sList_w[i]\n",
    "\n",
    "        mask_u = np.sign(q_u) * np.sign(VU) > 0\n",
    "        mask_w = np.sign(q_w) * np.sign(VW) > 0\n",
    "\n",
    "        return q_w * mask_w, q_u * mask_u\n",
    "    else:\n",
    "        return VW, VU\n",
    "\n",
    "def backTrackingLineSearch(X, y, weight_W, weight_U,norm21, norm1, pW, pU):\n",
    "    \"\"\"\n",
    "    :param it:\n",
    "    :param oldLoss:\n",
    "    :param data:\n",
    "    :param WW:\n",
    "    :param WU:\n",
    "    :param GW:\n",
    "    :param GU:\n",
    "    :param vGW:\n",
    "    :param vGU:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    alpha = 1.0\n",
    "    c = 0.5\n",
    "    tao = 0.9\n",
    "    LW, LU = sumCalDerivative(weight_W, weight_U, X, y)\n",
    "    m = (pW * LW + pU * LU).sum()\n",
    "    t = - c * m\n",
    "    loss = calLoss(X, y, weight_W, weight_U, norm21, norm1)\n",
    "\n",
    "    while True:\n",
    "        newW = weight_W - alpha*pW\n",
    "        newU = weight_U - alpha*pU\n",
    "\n",
    "        new_loss = calLoss(X, y, newW, newU, norm21, norm1)\n",
    "\n",
    "        if(loss > new_loss + alpha * t):\n",
    "            return newW, newU\n",
    "        else:\n",
    "            alpha = tao * alpha\n",
    "\n",
    "def fixOrthant(GW, weight_W, new_weight_W):\n",
    "    mask = (weight_W == 0) * np.sign(GW) + (weight_W != 0) * np.sign(weight_W)\n",
    "    mask = mask * new_weight_W > 0\n",
    "    return new_weight_W * mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "import pickle\n",
    "import time\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import roc_curve,roc_auc_score\n",
    "import random\n",
    "import logging\n",
    "\n",
    "class LSPLM:\n",
    "\n",
    "    def __init__(self,\n",
    "                 pieceNum = 12,\n",
    "                 iterNum = 1000,\n",
    "                 intercept = True,\n",
    "                 beta1 = 0.1,\n",
    "                 beta2 = 0.1,\n",
    "                 alpha = 0.001,\n",
    "                 epison = 10e-8,\n",
    "                 lamb = 0.1,\n",
    "                 beta = 0.1,\n",
    "                 terminate = False\n",
    "                 ):\n",
    "        \"\"\"\n",
    "        :param feaNum:  特征数\n",
    "        :param classNum:    类别数\n",
    "        :param iterNum:\n",
    "        :param intercept:\n",
    "        :param memoryNum:\n",
    "        :param beta:\n",
    "        :param lamb:\n",
    "        :param u_stdev:\n",
    "        :param w_stdev:\n",
    "        \"\"\"\n",
    "        self.pieceNum = pieceNum\n",
    "        self.iterNum = iterNum\n",
    "        self.intercept = intercept\n",
    "        self.beta = beta\n",
    "        self.lamb = lamb\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.alpha = alpha\n",
    "        self.N = 0\n",
    "        self.p = 0\n",
    "        self.terminate = terminate\n",
    "        self.epison = epison\n",
    "\n",
    "    def fit(self,X, y):\n",
    "        \"\"\"\n",
    "            训练ls-plm large scale piece-wise linear model\n",
    "        :param data:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        # np.random.seed(0)\n",
    "        N, p = X.shape\n",
    "        self.N = N\n",
    "        if self.intercept:\n",
    "            self.p = p + 1\n",
    "            pad = np.ones((N, p + 1))\n",
    "            pad[:,:-1] = X\n",
    "            X = pad\n",
    "            del pad\n",
    "        else:\n",
    "            self.p = p\n",
    "\n",
    "        ## Intialization\n",
    "        np.random.seed(0)\n",
    "        weight_W = np.random.normal(0,0.1, (self.pieceNum, self.p))\n",
    "        weight_U = np.random.normal(0,0.1, (self.pieceNum, self.p))\n",
    "        best_weight_W = np.random.normal(0,0.1, (self.pieceNum, self.p))\n",
    "        best_weight_U = np.random.normal(0,0.1, (self.pieceNum, self.p))\n",
    "        m_w = np.zeros((self.pieceNum, self.p))\n",
    "        m_u = np.zeros((self.pieceNum, self.p))\n",
    "        v_w = np.zeros((self.pieceNum, self.p))\n",
    "        v_u = np.zeros((self.pieceNum, self.p))\n",
    "        loss_before = calLoss(X, y, weight_W, weight_U, self.lamb, self.beta)\n",
    "        GW, GU = sumCalDerivative(weight_W, weight_U, X, y)\n",
    "        LW, LU = virtualGradient(weight_W, weight_U, GW, GU,self.beta,self.lamb)\n",
    "        it = 1\n",
    "        del GW,GU\n",
    "        loss_best = np.maximum\n",
    "        best_iter = 0\n",
    "        optimize_counter = 0\n",
    "        while it < self.iterNum:\n",
    "            print \"iter:%d, loss:%s\" % (it, loss_before)\n",
    "            start_time = time.time()\n",
    "            \n",
    "            GW, GU = sumCalDerivative(weight_W, weight_U, X, y)\n",
    "            newLW, newLU = virtualGradient(weight_W, weight_U, GW, GU,self.beta,self.lamb)\n",
    "            del GW,GU\n",
    "\n",
    "\n",
    "            m_w, m_u, v_w, v_u, PW, PU = adam(newLW, newLU, m_w, m_u, v_w, v_u, self.beta1, self.beta2, it, self.alpha, self.epison)\n",
    "\n",
    "            new_weight_W, new_weight_U = weight_W + PW, weight_U + PU\n",
    "\n",
    "            del PW, PU\n",
    "\n",
    "            new_weight_W = fixOrthant(newLW, weight_W, new_weight_W)\n",
    "            new_weight_U = fixOrthant(newLU, weight_U, new_weight_U)\n",
    "            loss_now = calLoss(X, y, new_weight_W, new_weight_U, self.lamb, self.beta)\n",
    "            if(loss_now < loss_best):\n",
    "                loss_best = loss_now\n",
    "                best_iter = it\n",
    "                best_weight_W = new_weight_W\n",
    "                best_weight_U = new_weight_U\n",
    "            if(loss_before < loss_now):\n",
    "                optimize_counter += 1\n",
    "                if(optimize_counter >= 10):\n",
    "                    self.weight_U = best_weight_U\n",
    "                    self.weight_W = best_weight_W\n",
    "                    print(\"use time: \", time.time() - start_time)\n",
    "                    print(\"The best result get at %d iteration with loss: %f\" % (best_iter, loss_best))\n",
    "                    return \"Done!\"\n",
    "            else:\n",
    "                optimize_counter = 0\n",
    "            \n",
    "\n",
    "            weight_U = new_weight_U\n",
    "            weight_W = new_weight_W\n",
    "            LW = newLW\n",
    "            LU = newLU\n",
    "            del newLW\n",
    "            del newLU\n",
    "            del new_weight_U\n",
    "            del new_weight_W\n",
    "            loss_before = loss_now\n",
    "            \n",
    "\n",
    "            it += 1\n",
    "\n",
    "\n",
    "        logging.info(\"============iterator : %s end ==========\" % it)\n",
    "        print(\"\")\n",
    "\n",
    "        print(\"The best result get at %d iteration with loss: %f\" % (best_iter, loss_best))\n",
    "        print(\"Done!\")\n",
    "        self.weight_W = best_weight_W\n",
    "        self.weight_U = best_weight_U\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        N, p = X.shape\n",
    "        if self.intercept:\n",
    "            pad = np.ones((N, p + 1))\n",
    "            pad[:,:-1] = X\n",
    "            X = pad\n",
    "            del pad\n",
    "        return np.array(map(lambda x: mlr(self.weight_W,self.weight_U,x),X))\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array(self.predict_proba(X) > 0.5, dtype = int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test\n",
    "X1 = np.random.normal(1,0.2, (100, 10))\n",
    "X2 = np.random.normal(-1,0.2, (100,10))\n",
    "y = np.zeros(200)\n",
    "for i in range(0,100):\n",
    "    y[i] = 1\n",
    "ls = LSPLM(iterNum=1000,lamb = 0.1,beta = 0.1,pieceNum=1)\n",
    "ls.fit(X,Y)\n",
    "y_test = ls.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 10)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(79.444532195606982, 0.056534021568401704, 0.15686732448500956)\n",
      "iter:1, loss:79.6579335417\n",
      "(78.797371346601707, 0.056423805812347919, 0.15646732502015478)\n",
      "iter:2, loss:79.0102624774\n",
      "(78.15458057639907, 0.056316216507825728, 0.15606733501039685)\n",
      "iter:3, loss:78.3669641279\n",
      "(77.516143492957397, 0.056211268193387988, 0.15566734994992495)\n",
      "iter:4, loss:77.7280221111\n",
      "(76.882043974494493, 0.056108975406856144, 0.15526736741919608)\n",
      "iter:5, loss:77.0934203173\n",
      "(76.25226604618878, 0.056009352630481506, 0.15486738690601609)\n",
      "iter:6, loss:76.4631427857\n",
      "(75.626793674135598, 0.055912414134031065, 0.15446740851657847)\n",
      "iter:7, loss:75.8371734968\n",
      "(75.005610705601754, 0.05581817391704872, 0.154067432540577)\n",
      "iter:8, loss:75.2154963121\n",
      "(74.388700859155065, 0.055726645689838109, 0.15366745936829679)\n",
      "iter:9, loss:74.5980949642\n",
      "(73.776047725279, 0.055637842863764664, 0.15326748949685581)\n",
      "iter:10, loss:73.9849530576\n",
      "(73.167634768774931, 0.055551778543902197, 0.15286752356259981)\n",
      "iter:11, loss:73.3760540709\n",
      "(72.604820526005042, 0.055477519711809559, 0.15253537111384402)\n",
      "iter:12, loss:72.8128334168\n",
      "(72.004551982950318, 0.05539673887983583, 0.15213541601848779)\n",
      "iter:13, loss:72.2120841378\n",
      "(71.408474453579885, 0.055335351904539289, 0.15181871132556035)\n",
      "iter:14, loss:71.6156285168\n",
      "(70.816570915642473, 0.055280305804071311, 0.15151877213907472)\n",
      "iter:15, loss:71.0233699936\n",
      "(70.22899717700443, 0.055233644645587165, 0.15127798477253582)\n",
      "iter:16, loss:70.4355088064\n",
      "(69.697065020458822, 0.05518233587616346, 0.15089569957744375)\n",
      "iter:17, loss:69.9031430559\n",
      "(69.117194843383444, 0.055136274290231803, 0.15059715033729149)\n",
      "iter:18, loss:69.322928268\n",
      "(68.541429383681802, 0.05509321525969732, 0.15029818084365043)\n",
      "iter:19, loss:68.7468207798\n",
      "(67.969753488551419, 0.055053274765386545, 0.15000014209448553)\n",
      "iter:20, loss:68.1748069054\n",
      "(67.402153991203733, 0.05501686017309948, 0.14970861055545623)\n",
      "iter:21, loss:67.6068794619\n",
      "(66.838718493266214, 0.05498248675665024, 0.14949843708111957)\n",
      "iter:22, loss:67.0431994171\n",
      "(66.279174802493102, 0.054932341956295067, 0.14913952878624931)\n",
      "iter:23, loss:66.4832466732\n",
      "(65.723771650617309, 0.054894756996589668, 0.14893176139087266)\n",
      "iter:24, loss:65.927598169\n",
      "(65.172137921652251, 0.054847344265141443, 0.14855309240966202)\n",
      "iter:25, loss:65.3755383583\n",
      "(64.624626104534173, 0.054812622123941571, 0.14833394586303902)\n",
      "iter:26, loss:64.8277726725\n",
      "(64.080856476304419, 0.054769227858177963, 0.14795197794307591)\n",
      "iter:27, loss:64.2835776821\n",
      "(63.541178550213665, 0.054738348821004951, 0.1477355224980848)\n",
      "iter:28, loss:63.7436524215\n",
      "(63.005209089576397, 0.054699429752478469, 0.14735721667575072)\n",
      "iter:29, loss:63.207265736\n",
      "(62.473293568206358, 0.054672277335817844, 0.14714159305625651)\n",
      "iter:30, loss:62.6751074386\n",
      "(61.945047019856119, 0.054637548924613068, 0.14676228884479034)\n",
      "iter:31, loss:62.1464468576\n",
      "(61.420820368488371, 0.054614053847901835, 0.14654613051978002)\n",
      "iter:32, loss:61.6219805529\n",
      "(60.900226457873266, 0.054585584139832166, 0.14623605349225446)\n",
      "iter:33, loss:61.1010480955\n",
      "(60.383617476209025, 0.054568831717301272, 0.14612022932051044)\n",
      "iter:34, loss:60.5843065372\n",
      "(59.870603936691026, 0.054571448315972097, 0.14590475493572427)\n",
      "iter:35, loss:60.0710801399\n",
      "(59.361539963798606, 0.054599328270832484, 0.14588912366872189)\n",
      "iter:36, loss:59.5620284157\n",
      "(58.856033510190215, 0.054621781795060602, 0.14571056280157277)\n",
      "iter:37, loss:59.0563658548\n",
      "(58.354441469427826, 0.054654089941444495, 0.14569508725608041)\n",
      "iter:38, loss:58.5547906466\n",
      "(57.856368918227673, 0.054681556895248444, 0.14551684096425718)\n",
      "iter:39, loss:58.0565673161\n",
      "(57.362175527892056, 0.054718280710058867, 0.14550160876949392)\n",
      "iter:40, loss:57.5623954174\n",
      "(56.871463163750327, 0.054750743332615016, 0.14532374074924956)\n",
      "iter:41, loss:57.0715376478\n",
      "(56.384594738610254, 0.054791864644000855, 0.14530877627672287)\n",
      "iter:42, loss:56.5846953795\n",
      "(55.901168488753385, 0.054829301724100499, 0.14513135259087273)\n",
      "iter:43, loss:56.1011291431\n",
      "(55.421551076041972, 0.054874800793253922, 0.14511671212621199)\n",
      "iter:44, loss:55.621542589\n",
      "(54.945336611822917, 0.05491718952105841, 0.14493987114041881)\n",
      "iter:45, loss:55.1451936725\n",
      "(54.472896058480295, 0.054997040743491314, 0.14498701751902662)\n",
      "iter:46, loss:54.6728801167\n",
      "(54.003818828232092, 0.055093283944546059, 0.14491099279025157)\n",
      "iter:47, loss:54.203823105\n",
      "(53.538480955182102, 0.055196436857110953, 0.14499747591725584)\n",
      "iter:48, loss:53.738674868\n",
      "(53.076467062374441, 0.055297659635813338, 0.14492306820044684)\n",
      "iter:49, loss:53.2766877902\n",
      "(52.618237447907845, 0.055405168454970267, 0.14532044077509015)\n",
      "iter:50, loss:52.8189630571\n",
      "(52.163243577965346, 0.055511209344265247, 0.14563200967204981)\n",
      "iter:51, loss:52.364386797\n",
      "(51.711891333202459, 0.055622845479600336, 0.14610485785104776)\n",
      "iter:52, loss:51.9136190365\n",
      "(51.263775619567483, 0.055733653667059471, 0.14642612998877744)\n",
      "iter:53, loss:51.4659354032\n",
      "(50.81929704636908, 0.055849585002620619, 0.14691213281153426)\n",
      "iter:54, loss:51.0220587642\n",
      "(50.378018558329963, 0.055965231629524374, 0.14724174083970465)\n",
      "iter:55, loss:50.5812255308\n",
      "(49.940344966035838, 0.056085388309530242, 0.14773046153284669)\n",
      "iter:56, loss:50.1441608159\n",
      "(49.50583021900249, 0.056205770186660869, 0.14806475797654989)\n",
      "iter:57, loss:49.7101007472\n",
      "(49.074887905744788, 0.056330077983068251, 0.14855484405852024)\n",
      "iter:58, loss:49.2797728278\n",
      "(48.647064567670185, 0.056455110171292545, 0.14889618663138263)\n",
      "iter:59, loss:48.8524158645\n",
      "(48.222780602859466, 0.056583504687937984, 0.14938765198851306)\n",
      "iter:60, loss:48.4287517595\n",
      "(47.801580146715928, 0.056713084981235388, 0.14974094533869822)\n",
      "iter:61, loss:48.008034177\n",
      "(47.383882943474596, 0.056845500458277701, 0.15023382051381995)\n",
      "iter:62, loss:47.5909622644\n",
      "(46.969242235033121, 0.05697948417130231, 0.15060586751345992)\n",
      "iter:63, loss:47.1768275867\n",
      "(46.558061912398387, 0.0571158541939965, 0.15110011103062271)\n",
      "iter:64, loss:46.7662778776\n",
      "(46.149921093631669, 0.057254049430351873, 0.15149641084476595)\n",
      "iter:65, loss:46.3586715539\n",
      "(45.745188696011127, 0.057394308991354753, 0.15199296886677904)\n",
      "iter:66, loss:45.9545759739\n",
      "(45.343438615935732, 0.057536487988876242, 0.15249489274866887)\n",
      "iter:67, loss:45.5534699967\n",
      "(44.944765557438792, 0.057680598007986909, 0.15303514665348161)\n",
      "iter:68, loss:45.1554813021\n",
      "(44.549206775330674, 0.057826662132849829, 0.15359477440625249)\n",
      "iter:69, loss:44.7606282119\n",
      "(44.157044157925881, 0.057974400048407038, 0.1540192068207972)\n",
      "iter:70, loss:44.3690377648\n",
      "(43.767675800717711, 0.058124227062843092, 0.15460108583978421)\n",
      "iter:71, loss:43.9804011136\n",
      "(43.381727668370779, 0.058275655824917533, 0.15501500214009889)\n",
      "iter:72, loss:43.5950183263\n",
      "(42.998538512175188, 0.058429133330346765, 0.15558635743368715)\n",
      "iter:73, loss:43.2125540029\n",
      "(42.618713608453639, 0.058584233594550499, 0.15599986822152456)\n",
      "iter:74, loss:42.8332977103\n",
      "(42.24159379906316, 0.058741324449291282, 0.15657805857761739)\n",
      "iter:75, loss:42.4569131821\n",
      "(41.86781116397588, 0.058900029682368397, 0.15699323785599939)\n",
      "iter:76, loss:42.0837044315\n",
      "(41.49670503265132, 0.059060670464832467, 0.15756914478673492)\n",
      "iter:77, loss:41.7133348479\n",
      "(41.128896030838042, 0.059240555153704071, 0.15807276544296187)\n",
      "iter:78, loss:41.3462093514\n",
      "(40.763724336472997, 0.059424417600312709, 0.15874846325700134)\n",
      "iter:79, loss:40.9818972173\n",
      "(40.401809133040594, 0.059609942581066555, 0.15926401930298095)\n",
      "iter:80, loss:40.6206830949\n",
      "(40.042464591467066, 0.059797366213461906, 0.15995768786392001)\n",
      "iter:81, loss:40.2622196455\n",
      "(39.68624291763242, 0.059986436613912369, 0.16053728950145082)\n",
      "iter:82, loss:39.9067666437\n",
      "(39.333009977596724, 0.060177223139491989, 0.16106401458128086)\n",
      "iter:83, loss:39.5542512153\n",
      "(38.982321348423234, 0.060369842343011584, 0.16175730961541127)\n",
      "iter:84, loss:39.2044485004\n",
      "(38.634713124523074, 0.060564049322065029, 0.1623267428546086)\n",
      "iter:85, loss:38.8576039167\n",
      "(38.289998164787939, 0.060759946591297034, 0.162864014674823)\n",
      "iter:86, loss:38.5136221261\n",
      "(37.9477995124413, 0.060955782256556734, 0.16354217330299456)\n",
      "iter:87, loss:38.172297468\n",
      "(37.608637278024084, 0.061142429296921, 0.16400228501029696)\n",
      "iter:88, loss:37.8337819923\n",
      "(37.272277665077873, 0.061330326401325588, 0.16444914770630331)\n",
      "iter:89, loss:37.4980571392\n",
      "(36.938404460320903, 0.061519530463267594, 0.16504184850024889)\n",
      "iter:90, loss:37.1649658393\n",
      "(36.607521506808986, 0.061709813800872038, 0.16549371074350627)\n",
      "iter:91, loss:36.8347250314\n",
      "(36.279355792915617, 0.061901326580520138, 0.16594916613006278)\n",
      "iter:92, loss:36.5072062856\n",
      "(35.95364469613888, 0.062094104741628832, 0.16654144580842808)\n",
      "iter:93, loss:36.1822802467\n",
      "(35.630875550237235, 0.062287926545180852, 0.16698615822554111)\n",
      "iter:94, loss:35.860149635\n",
      "(35.310743508383652, 0.062482953854472389, 0.16744919881576947)\n",
      "iter:95, loss:35.5406756611\n",
      "(34.993032475325897, 0.062679207352673807, 0.16804095684099229)\n",
      "iter:96, loss:35.2237526395\n",
      "(34.678213160811865, 0.06287647121203109, 0.16847956435201736)\n",
      "iter:97, loss:34.9095691964\n",
      "(34.365955718131332, 0.063074914234298979, 0.16894925831314456)\n",
      "iter:98, loss:34.5979798907\n",
      "(34.064566441692634, 0.063272331507611732, 0.16951319489127925)\n",
      "iter:99, loss:34.2973519681\n",
      "(33.757464174362212, 0.063472949616263361, 0.16994683775223601)\n",
      "iter:100, loss:33.9908839617\n",
      "(33.452853848746109, 0.063674718759179752, 0.17042218820320298)\n",
      "iter:101, loss:33.6869507557\n",
      "(33.150592650877456, 0.063877641278212327, 0.17101261340630913)\n",
      "iter:102, loss:33.3854829056\n",
      "(32.851118682443179, 0.06408151331433018, 0.17144199441751495)\n",
      "iter:103, loss:33.0866421902\n",
      "(32.554070066473869, 0.064286507286104147, 0.17192246325120286)\n",
      "iter:104, loss:32.790279037\n",
      "(32.259333291145929, 0.064492620054159983, 0.17251205715428253)\n",
      "iter:105, loss:32.4963379684\n",
      "(31.96733018847927, 0.06469965411159255, 0.17293793149012765)\n",
      "iter:106, loss:32.2049677741\n",
      "(31.677691040126071, 0.064907779632835075, 0.17342345907966175)\n",
      "iter:107, loss:31.9160222788\n",
      "(31.390351393566231, 0.065116987832251352, 0.1740129611794384)\n",
      "iter:108, loss:31.6294813426\n",
      "(31.15844750896029, 0.065326858886860725, 0.17462136507019549)\n",
      "iter:109, loss:31.3983957329\n",
      "(30.93236585586008, 0.065537187974208252, 0.1753092399859259)\n",
      "iter:110, loss:31.1732122838\n",
      "(30.708421145002735, 0.065747966934369934, 0.17609554646575235)\n",
      "iter:111, loss:30.9502646584\n",
      "(30.486337810973613, 0.065959020462120002, 0.17671411017719496)\n",
      "iter:112, loss:30.7290109416\n",
      "(30.26565160344343, 0.066170514815061532, 0.17740905327589682)\n",
      "iter:113, loss:30.5092311715\n",
      "(30.046330205308013, 0.066382442495222058, 0.17819251038155384)\n",
      "iter:114, loss:30.2909051582\n",
      "(29.828730681836824, 0.066594642282253466, 0.17880904983057436)\n",
      "iter:115, loss:30.0741343739\n",
      "(29.612378967789041, 0.066807311873681247, 0.17958563347895207)\n",
      "iter:116, loss:29.8587719131\n",
      "(29.397706794757369, 0.06702026355769844, 0.18020904661270845)\n",
      "iter:117, loss:29.6449361049\n",
      "(29.1842856824669, 0.067233665447799837, 0.18098232551246748)\n",
      "iter:118, loss:29.4325016734\n",
      "(28.972512137943689, 0.067447350361463543, 0.18160904345243389)\n",
      "iter:119, loss:29.2215685318\n",
      "(28.761988842473365, 0.067661469852583436, 0.18237804364678223)\n",
      "iter:120, loss:29.012028356\n",
      "(28.553079456437946, 0.067875875029857022, 0.18300904035432258)\n",
      "iter:121, loss:28.8039643718\n",
      "(28.345421097299599, 0.068090698107615019, 0.18377298164717337)\n",
      "iter:122, loss:28.5972847771\n",
      "(28.139341948890106, 0.068305810501449474, 0.18440903732479058)\n",
      "iter:123, loss:28.3920567967\n",
      "(27.934515998223347, 0.068521323494434752, 0.18516698122225955)\n",
      "iter:124, loss:28.1882043029\n",
      "(27.7312332731202, 0.068737130303928404, 0.18580903437091997)\n",
      "iter:125, loss:27.9857794378\n",
      "(27.529207513578971, 0.068953319987765091, 0.18655991424474533)\n",
      "iter:126, loss:27.7847207478\n",
      "(27.328687551988775, 0.069169808541144073, 0.1872090315005229)\n",
      "iter:127, loss:27.585066392\n",
      "(27.129430054750451, 0.069386662237249902, 0.18795167111827624)\n",
      "iter:128, loss:27.3867683881\n",
      "(26.931639378955158, 0.069603819880368664, 0.18860902872224233)\n",
      "iter:129, loss:27.1898522276\n",
      "(26.735118452858579, 0.069821325573937387, 0.18934219097321123)\n",
      "iter:130, loss:26.9942819694\n",
      "(26.540023823331484, 0.070039139539770465, 0.19000902604566769)\n",
      "iter:131, loss:26.8000719889\n",
      "(26.346207931433625, 0.07025728598700641, 0.19073149726566319)\n",
      "iter:132, loss:26.6071967147\n",
      "(26.153776435238157, 0.070475743276105993, 0.19140902348147071)\n",
      "iter:133, loss:26.415661202\n",
      "(25.962634075702322, 0.070694520053479773, 0.19211973700899579)\n",
      "iter:134, loss:26.2254483328\n",
      "(25.772833250265855, 0.070913607372632734, 0.1928090210415655)\n",
      "iter:135, loss:26.0365558787\n",
      "(25.584330878872574, 0.071133004785546197, 0.19350901987247157)\n",
      "iter:136, loss:25.8489729035\n",
      "(25.397077977504527, 0.071352728528609757, 0.19426231071663783)\n",
      "iter:137, loss:25.6626930167\n",
      "(25.211225138591093, 0.07157271607561011, 0.19490901764137103)\n",
      "iter:138, loss:25.4777068723\n",
      "(25.026606085609263, 0.071793024340652836, 0.19560901658840951)\n",
      "iter:139, loss:25.2940081265\n",
      "(24.843264997870939, 0.072013630665877668, 0.19630986838954229)\n",
      "iter:140, loss:25.1115884969\n",
      "(24.66119664220351, 0.072234532305655949, 0.19700901460820147)\n",
      "iter:141, loss:24.9304401891\n",
      "(24.48039075601065, 0.072455726574230092, 0.19770901368742008)\n",
      "iter:142, loss:24.7505554963\n",
      "(24.300840482336724, 0.072677210794913794, 0.19840901281642115)\n",
      "iter:143, loss:24.5719267059\n",
      "(24.122538152343111, 0.072898982325081768, 0.19910901199805958)\n",
      "iter:144, loss:24.3945461467\n",
      "(23.945476128922039, 0.073121038550772205, 0.1998090112353651)\n",
      "iter:145, loss:24.2184061787\n",
      "(23.769646806781445, 0.073343376886358821, 0.2005090105315763)\n",
      "iter:146, loss:24.0434991942\n",
      "(23.595042612529095, 0.073591056842545174, 0.20126625683833002)\n",
      "iter:147, loss:23.8698999262\n",
      "(23.421656004625035, 0.073857608850098941, 0.20206625610371562)\n",
      "iter:148, loss:23.6975798696\n",
      "(23.249479473720221, 0.074124281598747899, 0.2028662554391108)\n",
      "iter:149, loss:23.5264700108\n",
      "(23.078505542686301, 0.074391073790113268, 0.20366625484836393)\n",
      "iter:150, loss:23.3565628713\n",
      "(22.908726766515684, 0.074662077925111758, 0.20452536781747557)\n",
      "iter:151, loss:23.1879142123\n",
      "(22.740135731616974, 0.074936096691912091, 0.20542536491178148)\n",
      "iter:152, loss:23.0204971932\n",
      "(22.572725057645876, 0.075210313743740986, 0.2063253620001643)\n",
      "iter:153, loss:22.8542607334\n",
      "(22.406487397148311, 0.075484726919438694, 0.20722535907968528)\n",
      "iter:154, loss:22.6891974831\n",
      "(22.241415434630223, 0.075759334087772356, 0.20812535614960553)\n",
      "iter:155, loss:22.5253001249\n",
      "(22.077501886986646, 0.076034133146834743, 0.20902535320964546)\n",
      "iter:156, loss:22.3625613733\n",
      "(21.91473950363503, 0.076309122023542481, 0.20992535025958634)\n",
      "iter:157, loss:22.2009739759\n",
      "(21.753121066572945, 0.07658429867316624, 0.21082534729920607)\n",
      "iter:158, loss:22.0405307125\n",
      "(21.592639390420509, 0.076859661078873168, 0.21172534432827064)\n",
      "iter:159, loss:21.8812243958\n",
      "(21.433287322458298, 0.077135207251277982, 0.21262534134653116)\n",
      "iter:160, loss:21.7230478711\n",
      "(21.275057742661435, 0.077410935228002395, 0.21352533835372345)\n",
      "iter:161, loss:21.5659940162\n",
      "(21.117943563730492, 0.077686843073242182, 0.21442533534956656)\n",
      "iter:162, loss:21.4100557422\n",
      "(20.961937731119168, 0.077962928877342241, 0.21532533233376189)\n",
      "iter:163, loss:21.2552259923\n",
      "(20.807033223058763, 0.078239190756379223, 0.21622532930599167)\n",
      "iter:164, loss:21.1014977431\n",
      "(20.653223050579523, 0.078515626851751549, 0.21712532626591777)\n",
      "iter:165, loss:20.9488640037\n",
      "(20.500500257528934, 0.078792235329776805, 0.21802532321318013)\n",
      "iter:166, loss:20.7973178161\n",
      "(20.348857920586795, 0.079069014381296418, 0.21892532014739541)\n",
      "iter:167, loss:20.6468522551\n",
      "(20.198289149277493, 0.079345962221287161, 0.21982531706815492)\n",
      "iter:168, loss:20.4974604286\n",
      "(20.048787085979114, 0.079623077088479835, 0.22072531397502312)\n",
      "iter:169, loss:20.349135477\n",
      "(19.900344905929707, 0.079900357244984496, 0.22162531086753515)\n",
      "iter:170, loss:20.201870574\n",
      "(19.752955817230642, 0.080177800975922517, 0.22252530774519494)\n",
      "iter:171, loss:20.055658926\n",
      "(19.606613060847106, 0.080455406589065109, 0.22342530460747256)\n",
      "iter:172, loss:19.910493772\n",
      "(19.461309910605749, 0.08073317241447818, 0.22432530145380192)\n",
      "iter:173, loss:19.7663683845\n",
      "(19.317039673189569, 0.081011096804173635, 0.2252252982835774)\n",
      "iter:174, loss:19.6232760683\n",
      "(19.17379568813006, 0.081289178131766671, 0.22612529509615104)\n",
      "iter:175, loss:19.4812101614\n",
      "(19.031571327796581, 0.081567414792139192, 0.22702529189082887)\n",
      "iter:176, loss:19.3401640345\n",
      "(18.890359997383243, 0.081845805201109179, 0.22792528866686743)\n",
      "iter:177, loss:19.2001310913\n",
      "(18.750155134892811, 0.082124347795105856, 0.22882528542346903)\n",
      "iter:178, loss:19.0611047681\n",
      "(18.61095021111835, 0.082403041030850499, 0.22972528215977769)\n",
      "iter:179, loss:18.9230785343\n",
      "(18.472738729622151, 0.082681883385042898, 0.23062527887487383)\n",
      "iter:180, loss:18.7860458919\n",
      "(18.335514226712057, 0.082960873354053374, 0.2315252755677687)\n",
      "iter:181, loss:18.6500003756\n",
      "(18.199270271415358, 0.083240009453620034, 0.23242527223739842)\n",
      "iter:182, loss:18.5149355531\n",
      "(18.064000465450167, 0.083519290218551437, 0.23332526888261707)\n",
      "iter:183, loss:18.3808450246\n",
      "(17.929698443194429, 0.083798714202434357, 0.23422526550218903)\n",
      "iter:184, loss:18.2477224229\n",
      "(17.796357871652347, 0.084078279977346737, 0.23512526209478085)\n",
      "iter:185, loss:18.1155614137\n",
      "(17.663972450418527, 0.084357986133575452, 0.23602525865895196)\n",
      "iter:186, loss:17.9843556952\n",
      "(17.532535911639705, 0.084637831279339187, 0.23692525519314414)\n",
      "iter:187, loss:17.8540989981\n",
      "(17.402042019974061, 0.08491781404051596, 0.23782525169567059)\n",
      "iter:188, loss:17.7247850857\n",
      "(17.272484572548251, 0.085197933060375375, 0.23872524816470256)\n",
      "iter:189, loss:17.5964077538\n",
      "(17.143857398912093, 0.085478186999315572, 0.23962524459825546)\n",
      "iter:190, loss:17.4689608305\n",
      "(17.016154360990907, 0.085758574534604698, 0.2405252409941725)\n",
      "iter:191, loss:17.3424381765\n",
      "(16.889369353035523, 0.086039094360126689, 0.24142523735010732)\n",
      "iter:192, loss:17.2168336847\n",
      "(16.763496301569941, 0.086319745186131558, 0.24232523366350317)\n",
      "iter:193, loss:17.0921412804\n",
      "(16.63852916533677, 0.086600525738990047, 0.24322522993157047)\n",
      "iter:194, loss:16.968354921\n",
      "(16.514461935240213, 0.08688143476095217, 0.24412522615126142)\n",
      "iter:195, loss:16.8454685962\n",
      "(16.39128863428672, 0.087162471009910217, 0.24502522231924054)\n",
      "iter:196, loss:16.7234763276\n",
      "(16.269003317523218, 0.087443633259165598, 0.24592521843185217)\n",
      "iter:197, loss:16.6023721692\n",
      "(16.14760007197297, 0.087724920297199749, 0.24682521448508321)\n",
      "iter:198, loss:16.4821502068\n",
      "(16.027073016568842, 0.088006330927448875, 0.2477252104745202)\n",
      "iter:199, loss:16.362804558\n",
      "(15.907416302084101, 0.088287863968082581, 0.24862520639530136)\n",
      "iter:200, loss:16.2443293724\n",
      "(15.788624111060409, 0.088569518251786147, 0.24952520224206093)\n",
      "iter:201, loss:16.1267188316\n",
      "(15.670690657733175, 0.088851292625546641, 0.25042519800886537)\n",
      "iter:202, loss:16.0099671484\n",
      "(15.553610187953883, 0.089133185950442534, 0.25132519368914025)\n",
      "iter:203, loss:15.8940685676\n",
      "(15.437376979109404, 0.089415197101436805, 0.25222518927558596)\n",
      "iter:204, loss:15.7790173655\n",
      "(15.321985340037878, 0.089697324967173697, 0.25312518476007967)\n",
      "iter:205, loss:15.6648078498\n",
      "(15.207429610941098, 0.08997956844977878, 0.25402518013356223)\n",
      "iter:206, loss:15.5514343595\n",
      "(15.093704163292937, 0.090261926464662273, 0.25492517538590548)\n",
      "iter:207, loss:15.4388912651\n",
      "(14.980803399743461, 0.090544397940325885, 0.25582517050575837)\n",
      "iter:208, loss:15.3271729682\n",
      "(14.868721754018178, 0.090826981818172697, 0.25672516548036589)\n",
      "iter:209, loss:15.2162739013\n",
      "(14.757453690811907, 0.091109677052320232, 0.25762516029535543)\n",
      "iter:210, loss:15.1061885282\n",
      "(14.646993705676337, 0.091392482609416723, 0.25852515493448591)\n",
      "iter:211, loss:14.9969113432\n",
      "(14.537336324900613, 0.091675397468460304, 0.25942514937934813)\n",
      "iter:212, loss:14.8884368717\n",
      "(14.428476105383389, 0.091958420620621303, 0.26032514360900944)\n",
      "iter:213, loss:14.7807596696\n",
      "(14.320407634495245, 0.092241551069067423, 0.26122513759958771)\n",
      "iter:214, loss:14.6738743232\n",
      "(14.213125529929304, 0.092524787828791755, 0.2621251313237391)\n",
      "iter:215, loss:14.5677754491\n",
      "(14.106624439538002, 0.092808129926443717, 0.26302512475003964)\n",
      "iter:216, loss:14.4624576942\n",
      "(14.000899041152906, 0.093091576400162676, 0.26392511784223255)\n",
      "iter:217, loss:14.3579157354\n",
      "(13.895944042383508, 0.09337512629941426, 0.26482511055831121)\n",
      "iter:218, loss:14.2541442792\n",
      "(13.791754180390827, 0.093658778684829511, 0.2657251028493906)\n",
      "iter:219, loss:14.1511380619\n",
      "(13.688324221628726, 0.093942532628046346, 0.26662509465831308)\n",
      "iter:220, loss:14.0488918489\n",
      "(13.585648961545122, 0.094226387211553894, 0.26752508591791407)\n",
      "iter:221, loss:13.9474004347\n",
      "(13.483723224232197, 0.094510341528539016, 0.26842507654884934)\n",
      "iter:222, loss:13.8466586423\n",
      "(13.382541862011147, 0.094794394682735511, 0.26932506645685267)\n",
      "iter:223, loss:13.7466613232\n",
      "(13.282099754932187, 0.095078545788275542, 0.27022505552925069)\n",
      "iter:224, loss:13.6474033562\n",
      "(13.182391810164004, 0.095362793969543336, 0.27112504363049211)\n",
      "iter:225, loss:13.5488796478\n",
      "(13.083412961236855, 0.095647138361031281, 0.27202503059636834)\n",
      "iter:226, loss:13.4510851302\n",
      "(12.985158167090852, 0.095931578107197935, 0.27292501622646864)\n",
      "iter:227, loss:13.3540147614\n",
      "(12.887622410861205, 0.096216112362328216, 0.27382500027423762)\n",
      "iter:228, loss:13.2576635235\n",
      "(12.790800698304642, 0.096500740290395404, 0.27472498243373433)\n",
      "iter:229, loss:13.162026421\n",
      "(12.694688055730975, 0.096785461064924916, 0.27562496232180872)\n",
      "iter:230, loss:13.0670984791\n",
      "(12.599279527243747, 0.097070273868859511, 0.27652493945383311)\n",
      "iter:231, loss:12.9728747406\n",
      "(12.504570171005049, 0.097355177894425715, 0.27742491321026946)\n",
      "iter:232, loss:12.8793502621\n",
      "(12.410555054106592, 0.097640172343001083, 0.27832488279005452)\n",
      "iter:233, loss:12.7865201092\n",
      "(12.317229245430019, 0.097925256424981497, 0.27922484714483081)\n",
      "iter:234, loss:12.694379349\n",
      "(12.224587805583038, 0.098210429359647855, 0.28012480488511793)\n",
      "iter:235, loss:12.6029230398\n",
      "(12.132625772569899, 0.098495690375030989, 0.28102475414520656)\n",
      "iter:236, loss:12.5121462171\n",
      "(12.041338141271803, 0.098781038707772884, 0.28192469238756784)\n",
      "iter:237, loss:12.4220438724\n",
      "(11.950719834147726, 0.099066473602982708, 0.28282461612033671)\n",
      "iter:238, loss:12.3326109239\n",
      "(11.860765660215753, 0.099351994314085867, 0.28372452049633001)\n",
      "iter:239, loss:12.243842175\n",
      "(11.771470260750025, 0.099637600102666785, 0.28462439877168427)\n",
      "iter:240, loss:12.1557322596\n",
      "(11.682828047335221, 0.099923290238315809, 0.28552424166437751)\n",
      "iter:241, loss:12.0682755792\n",
      "(11.594833160778467, 0.10020906399851437, 0.28642403686051349)\n",
      "iter:242, loss:11.9814662616\n",
      "(11.507479532472322, 0.10049492066864285, 0.28732376941527221)\n",
      "iter:243, loss:11.8952982226\n",
      "(11.42076119351046, 0.10078085954223909, 0.28822342443951232)\n",
      "iter:244, loss:11.8097654775\n",
      "(11.334672847072211, 0.10106687992147456, 0.28912299240944411)\n",
      "iter:245, loss:11.7248627194\n",
      "(11.249210103396608, 0.10135298111725698, 0.29002247179062962)\n",
      "iter:246, loss:11.6405855563\n",
      "(11.164369284150263, 0.10163916244885772, 0.2909218676796016)\n",
      "iter:247, loss:11.5569303143\n",
      "(11.08014734409667, 0.10192542324354655, 0.29182119121311861)\n",
      "iter:248, loss:11.4738939586\n",
      "(10.996539606884829, 0.1022117628348853, 0.29272043872511611)\n",
      "iter:249, loss:11.3914718084\n",
      "(10.913566135469571, 0.10249818057703888, 0.29361983631475402)\n",
      "iter:250, loss:11.3096841524\n",
      "(10.820626873259755, 0.10278471867769119, 0.29460790623998784)\n",
      "iter:251, loss:11.2180194982\n",
      "(10.718463597934619, 0.10307152057793741, 0.29565111524639504)\n",
      "iter:252, loss:11.1171862338\n",
      "(10.616755729403538, 0.10335857799395534, 0.29668952450867786)\n",
      "iter:253, loss:11.0168038319\n",
      "(10.515944598976683, 0.10364599265866306, 0.29774755490517613)\n",
      "iter:254, loss:10.9173381465\n",
      "(10.416065449966872, 0.10393390514569152, 0.29883304961502627)\n",
      "iter:255, loss:10.8188324047\n",
      "(10.317114304076922, 0.10422231681964811, 0.29993008914228586)\n",
      "iter:256, loss:10.72126671\n",
      "(10.219083365416093, 0.10451119059246095, 0.30102950680755036)\n",
      "iter:257, loss:10.6246240628\n",
      "(10.121964518316874, 0.10480051159553375, 0.30212934241233264)\n",
      "iter:258, loss:10.5288943723\n",
      "(10.025749673973809, 0.10508903861104651, 0.30314104483004362)\n",
      "iter:259, loss:10.4339797574\n",
      "(9.9304308103225196, 0.1053775777758762, 0.30414103915289714)\n",
      "iter:260, loss:10.3399494273\n",
      "(9.8359999591052585, 0.10566627539959234, 0.30514103344260829)\n",
      "iter:261, loss:10.2468072679\n",
      "(9.7424492191829639, 0.10595513018718827, 0.30614102772058482)\n",
      "iter:262, loss:10.1545453771\n",
      "(9.6497707541784639, 0.10624414085681666, 0.30714102199060189)\n",
      "iter:263, loss:10.063155917\n",
      "(9.557956790674309, 0.1065333061398079, 0.30814101625321805)\n",
      "iter:264, loss:9.97263111307\n",
      "(9.4669996175774855, 0.10682262478054727, 0.30914101050852016)\n",
      "iter:265, loss:9.88296325287\n",
      "(9.3768915857143345, 0.10711209553632282, 0.31014100475653228)\n",
      "iter:266, loss:9.79414468601\n",
      "(9.2876251074594194, 0.1074017171771699, 0.3111409989972696)\n",
      "iter:267, loss:9.70616782363\n",
      "(9.1991926563687496, 0.10769148848571736, 0.31214099323074596)\n",
      "iter:268, loss:9.61902513809\n",
      "(9.111586766813053, 0.1079814082570356, 0.31314098745697444)\n",
      "iter:269, loss:9.53270916253\n",
      "(9.0248000336108696, 0.10827147529848669, 0.31414098167596732)\n",
      "iter:270, loss:9.44721249059\n",
      "(8.9388251116613624, 0.10856168842957642, 0.3151409758877366)\n",
      "iter:271, loss:9.36252777598\n",
      "(8.8536547155770098, 0.10885204648180845, 0.31614097009229325)\n",
      "iter:272, loss:9.27864773215\n",
      "(8.7692816193160166, 0.10914254829854038, 0.31714096428964789)\n",
      "iter:273, loss:9.1955651319\n",
      "(8.6856986558148321, 0.10943319273484167, 0.31814095847981039)\n",
      "iter:274, loss:9.11327280703\n",
      "(8.6028987166204924, 0.10972397865735367, 0.31914095266279002)\n",
      "iter:275, loss:9.03176364794\n",
      "(8.5208747515230652, 0.11001490494415125, 0.32014094683859534)\n",
      "iter:276, loss:8.95103060331\n",
      "(8.4396197681882104, 0.11030597048460655, 0.32114094100723439)\n",
      "iter:277, loss:8.87106667968\n",
      "(8.359126831789828, 0.11059717417925433, 0.32214093516871456)\n",
      "iter:278, loss:8.79186494114\n",
      "(8.2793890646429524, 0.11088851493965926, 0.32314092932304228)\n",
      "iter:279, loss:8.71341850891\n",
      "(8.2003996458368444, 0.11117999168828495, 0.32414092347022383)\n",
      "iter:280, loss:8.635720561\n",
      "(8.1221518108684201, 0.11147160335836473, 0.32514091761026431)\n",
      "iter:281, loss:8.55876433184\n",
      "(8.0446388512760461, 0.11176334889377411, 0.32614091174316862)\n",
      "iter:282, loss:8.48254311191\n",
      "(7.9678541142736066, 0.11205522724890493, 0.32714090586894073)\n",
      "iter:283, loss:8.40705024739\n",
      "(7.8917910023852205, 0.11234723738854135, 0.328140899987584)\n",
      "iter:284, loss:8.33227913976\n",
      "(7.8164429730802087, 0.11263937828773724, 0.32914089409910108)\n",
      "iter:285, loss:8.25822324547\n",
      "(7.7418035384087833, 0.11293164893169527, 0.33014088820349408)\n",
      "iter:286, loss:8.18487607554\n",
      "(7.6678662646382145, 0.11322404831564786, 0.33114088230076433)\n",
      "iter:287, loss:8.11223119525\n",
      "(7.5946247718895687, 0.11351657544473932, 0.33214087639091244)\n",
      "iter:288, loss:8.04028222373\n",
      "(7.5220727337752811, 0.11380922933390979, 0.33314087047393848)\n",
      "iter:289, loss:7.96902283358\n",
      "(7.4502038770371826, 0.11410200900778061, 0.33414086454984165)\n",
      "iter:290, loss:7.89844675059\n",
      "(7.3790119811854762, 0.11439491350054132, 0.33514085861862064)\n",
      "iter:291, loss:7.8285477533\n",
      "(7.3084908781383131, 0.11468794185583803, 0.33614085268027322)\n",
      "iter:292, loss:7.75931967267\n",
      "(7.2386344518623558, 0.11498109312666333, 0.33714084673479672)\n",
      "iter:293, loss:7.69075639172\n",
      "(7.169436638014, 0.11527436637524757, 0.33814084078218776)\n",
      "iter:294, loss:7.62285184517\n",
      "(7.1008914235816061, 0.1155677606729517, 0.33914083482244189)\n",
      "iter:295, loss:7.55560001908\n",
      "(7.0329928465286038, 0.11586127510016149, 0.34014082885555424)\n",
      "iter:296, loss:7.48899495048\n",
      "(6.9657349954375629, 0.11615490874618289, 0.34114082288151931)\n",
      "iter:297, loss:7.42303072707\n",
      "(6.8991120091551634, 0.1164486607091392, 0.34214081690033066)\n",
      "iter:298, loss:7.35770148676\n",
      "(6.8331180764383239, 0.11674253009586927, 0.34314081091198123)\n",
      "iter:299, loss:7.29300141745\n",
      "(6.7677474356012377, 0.11703651602182702, 0.34414080491646321)\n",
      "iter:300, loss:7.22892475654\n",
      "(6.7029943741635245, 0.1173306176109825, 0.34514079891376798)\n",
      "iter:301, loss:7.16546579069\n",
      "(6.6388532284995083, 0.11762483399572406, 0.34614079290388644)\n",
      "iter:302, loss:7.1026188554\n",
      "(6.5753183834885984, 0.1179191643167618, 0.34714078688680844)\n",
      "iter:303, loss:7.04037833469\n",
      "(6.5123842721667975, 0.11821360772303245, 0.34814078086252326)\n",
      "iter:304, loss:6.97873866075\n",
      "(6.4500453753794806, 0.11850816337160515, 0.34914077483101935)\n",
      "iter:305, loss:6.91769431358\n",
      "(6.3882962214352412, 0.11880283042758888, 0.35014076879228445)\n",
      "iter:306, loss:6.85723982066\n",
      "(6.3271313857611089, 0.11909760806404074, 0.35114076274630551)\n",
      "iter:307, loss:6.79736975657\n",
      "(6.2665454905589293, 0.11939249546187553, 0.35214075669306877)\n",
      "iter:308, loss:6.73807874271\n",
      "(6.2065332044630663, 0.11968749180977666, 0.35314075063255962)\n",
      "iter:309, loss:6.67936144691\n",
      "(6.1470892421993488, 0.11998259630410796, 0.35414074456476263)\n",
      "iter:310, loss:6.62121258307\n",
      "(6.0882083642454292, 0.12027780814882677, 0.35514073848966182)\n",
      "iter:311, loss:6.56362691088\n",
      "(6.0298853764924161, 0.12057312655539809, 0.35614073240724003)\n",
      "iter:312, loss:6.50659923546\n",
      "(5.9721151299078397, 0.12086855074271002, 0.35714072631747973)\n",
      "iter:313, loss:6.45012440697\n",
      "(5.9148925202001195, 0.12116407993698985, 0.35814072022036236)\n",
      "iter:314, loss:6.39419732036\n",
      "(5.8582124874843027, 0.12145971337172184, 0.35914071411586845)\n",
      "iter:315, loss:6.33881291497\n",
      "(5.8020700159493046, 0.12175545028756546, 0.36014070800397802)\n",
      "iter:316, loss:6.28396617424\n",
      "(5.7464601335265293, 0.12205128993227515, 0.36114070188467001)\n",
      "iter:317, loss:6.22965212534\n",
      "(5.6913779115599885, 0.12234723156062073, 0.36214069575792257)\n",
      "iter:318, loss:6.17586583888\n",
      "(5.6368184644778712, 0.12264327443430921, 0.36314068962371321)\n",
      "iter:319, loss:6.12260242854\n",
      "(5.5827769494655728, 0.12293941782190715, 0.36414068348201845)\n",
      "iter:320, loss:6.06985705077\n",
      "(5.5292485661402972, 0.12323566099876443, 0.36514067733281386)\n",
      "iter:321, loss:6.01762490447\n",
      "(5.4762285562270581, 0.12353200324693875, 0.36614067117607435)\n",
      "iter:322, loss:5.96590123065\n",
      "(5.4237122032363105, 0.1238284438551211, 0.36714066501177395)\n",
      "iter:323, loss:5.9146813121\n",
      "(5.3716948321430795, 0.12412498211856238, 0.36814065883988567)\n",
      "iter:324, loss:5.8639604731\n",
      "(5.320171809067654, 0.12442161733900062, 0.36914065266038182)\n",
      "iter:325, loss:5.81373407907\n",
      "(5.269138540957794, 0.12471834882458942, 0.3701406464732338)\n",
      "iter:326, loss:5.76399753626\n",
      "(5.2185904752726202, 0.12501517588982711, 0.37114064027841209)\n",
      "iter:327, loss:5.71474629144\n",
      "(5.1685230996679845, 0.12531209785548694, 0.3721406340758861)\n",
      "iter:328, loss:5.6659758316\n",
      "(5.118931941683484, 0.12560911404854802, 0.37314062786562463)\n",
      "iter:329, loss:5.6176816836\n",
      "(5.0698125684311126, 0.12590622380212724, 0.37414062164759537)\n",
      "iter:330, loss:5.56985941388\n",
      "(5.0211605862854611, 0.12620342645541191, 0.37514061542176536)\n",
      "iter:331, loss:5.52250462816\n",
      "(4.972971640575591, 0.1265007213535935, 0.37614060918810022)\n",
      "iter:332, loss:5.47561297112\n",
      "(4.9252414152785517, 0.12679810784780188, 0.37714060294656515)\n",
      "iter:333, loss:5.42918012607\n",
      "(4.8779656327145027, 0.12709558529504067, 0.37814059669712408)\n",
      "iter:334, loss:5.38320181471\n",
      "(4.8311400532434785, 0.12739315305812321, 0.37914059043974013)\n",
      "iter:335, loss:5.33767379674\n",
      "(4.7847604749639023, 0.12769081050560946, 0.38014058417437541)\n",
      "iter:336, loss:5.29259186964\n",
      "(4.7388227334126096, 0.12798855701174353, 0.38114057790099104)\n",
      "iter:337, loss:5.24795186833\n",
      "(4.6933227012667134, 0.12828639195639227, 0.38214057161954718)\n",
      "iter:338, loss:5.20374966484\n",
      "(4.6482562880469898, 0.12858431472498427, 0.38314056533000301)\n",
      "iter:339, loss:5.1599811681\n",
      "(4.6036194398230608, 0.12888232470844987, 0.38414055903231664)\n",
      "iter:340, loss:5.11664232356\n",
      "(4.559408138920193, 0.12918042130316179, 0.38514055272644543)\n",
      "iter:341, loss:5.07372911295\n",
      "(4.5156184036278111, 0.12947860391087665, 0.3861405464123453)\n",
      "iter:342, loss:5.03123755395\n",
      "(4.4722462879097131, 0.12977687193867699, 0.38714054008997145)\n",
      "iter:343, loss:4.98916369994\n",
      "(4.4292878811159779, 0.13007522479891417, 0.38814053375927793)\n",
      "iter:344, loss:4.94750363967\n",
      "(4.386739307696546, 0.13037366190915198, 0.38914052742021776)\n",
      "iter:345, loss:4.90625349703\n",
      "(4.3445967269165644, 0.13067218269211076, 0.39014052107274289)\n",
      "iter:346, loss:4.86540943068\n",
      "(4.3028563325733939, 0.13097078657561254, 0.39114051471680411)\n",
      "iter:347, loss:4.82496763387\n",
      "(4.2615143527153228, 0.13126947299252642, 0.39214050835235142)\n",
      "iter:348, loss:4.78492433406\n",
      "(4.2205670493620291, 0.13156824138071513, 0.39314050197933337)\n",
      "iter:349, loss:4.74527579272\n",
      "(4.180010718226721, 0.13186709118298173, 0.39414049559769748)\n",
      "iter:350, loss:4.70601830501\n",
      "(4.1398416884399989, 0.13216602184701731, 0.39514048920739026)\n",
      "iter:351, loss:4.66714819949\n",
      "(4.1000563222754725, 0.13246503282534933, 0.39614048280835712)\n",
      "iter:352, loss:4.62866183791\n",
      "(4.0606510148770116, 0.13276412357529022, 0.39714047640054218)\n",
      "iter:353, loss:4.59055561485\n",
      "(4.0216221939878176, 0.13306329355888721, 0.39814046998388841)\n",
      "iter:354, loss:4.55282595753\n",
      "(3.9829663196811165, 0.13336254224287217, 0.39914046355833777)\n",
      "iter:355, loss:4.51546932548\n",
      "(3.9446798840926252, 0.13366186909861238, 0.40014045712383084)\n",
      "iter:356, loss:4.47848221032\n",
      "(3.9067594111547344, 0.13396127360206198, 0.40114045068030707)\n",
      "iter:357, loss:4.44186113544\n",
      "(3.8692014563323758, 0.13426075523371367, 0.40214044422770467)\n",
      "iter:358, loss:4.40560265579\n",
      "(3.8320026063606205, 0.13456031347855135, 0.4031404377659607)\n",
      "iter:359, loss:4.36970335761\n",
      "(3.7951594789840186, 0.13485994782600319, 0.40414043129501104)\n",
      "iter:360, loss:4.33415985811\n",
      "(3.7586687226975881, 0.13515965776989511, 0.40514042481479012)\n",
      "iter:361, loss:4.29896880528\n",
      "(3.7225270164895723, 0.13545944280840502, 0.40614041832523101)\n",
      "iter:362, loss:4.26412687762\n",
      "(3.6867310695858952, 0.13575930244401765, 0.40714041182626598)\n",
      "iter:363, loss:4.22963078386\n",
      "(3.6512776211962867, 0.13605923618347979, 0.40814040531782547)\n",
      "iter:364, loss:4.1954772627\n",
      "(3.6161634402621559, 0.13635924353775603, 0.40914039879983899)\n",
      "iter:365, loss:4.1616630826\n",
      "(3.5813853252061438, 0.13665932402198516, 0.41014039227223426)\n",
      "iter:366, loss:4.1281850415\n",
      "(3.5469401036833816, 0.13695947715543708, 0.41114038573493822)\n",
      "iter:367, loss:4.09503996657\n",
      "(3.5128246323344388, 0.1372597024614701, 0.41214037918787583)\n",
      "iter:368, loss:4.06222471398\n",
      "(3.4790357965399674, 0.13755999946748895, 0.41314037263097125)\n",
      "iter:369, loss:4.02973616864\n",
      "(3.4455705101770362, 0.13786036770490306, 0.41414036606414684)\n",
      "iter:370, loss:3.99757124395\n",
      "(3.4124257153771489, 0.13816080670908548, 0.41514035948732364)\n",
      "iter:371, loss:3.96572688157\n",
      "(3.3795983822859363, 0.13846131601933237, 0.41614035290042112)\n",
      "iter:372, loss:3.93420005121\n",
      "(3.3470855088245428, 0.13876189517882262, 0.41714034630335778)\n",
      "iter:373, loss:3.90298775031\n",
      "(3.3148841204526751, 0.13906254373457852, 0.41814033969604997)\n",
      "iter:374, loss:3.87208700388\n",
      "(3.2829912699333184, 0.13936326123742621, 0.41914033307841292)\n",
      "iter:375, loss:3.84149486425\n",
      "(3.2514040370991073, 0.13966404724195722, 0.42014032645036031)\n",
      "iter:376, loss:3.81120841079\n",
      "(3.2201195286203959, 0.13996490130649011, 0.42114031981180439)\n",
      "iter:377, loss:3.78122474974\n",
      "(3.189134877774932, 0.14026582299303259, 0.42214031316265538)\n",
      "iter:378, loss:3.75154101393\n",
      "(3.1584472442192166, 0.14056681186724421, 0.42314030650282253)\n",
      "iter:379, loss:3.72215436259\n",
      "(3.1280538137614902, 0.14086786749839939, 0.4241402998322128)\n",
      "iter:380, loss:3.69306198109\n",
      "(3.0979517981363713, 0.14116898945935091, 0.42514029315073243)\n",
      "iter:381, loss:3.66426108075\n",
      "(3.0681384347811171, 0.14147017732649389, 0.42614028645828494)\n",
      "iter:382, loss:3.63574889857\n",
      "(3.0386109866135178, 0.14177143067973003, 0.42714027975477314)\n",
      "iter:383, loss:3.60752269705\n",
      "(3.0093667418114234, 0.14207274910243253, 0.42814027304009744)\n",
      "iter:384, loss:3.57957976395\n",
      "(2.9804030135938535, 0.14237413218141101, 0.42914026631415703)\n",
      "iter:385, loss:3.55191741209\n",
      "(2.9517171400037765, 0.14267557950687734, 0.43014025957684876)\n",
      "iter:386, loss:3.52453297909\n",
      "(2.9233064836924476, 0.14297709067241152, 0.43114025282806856)\n",
      "iter:387, loss:3.49742382719\n",
      "(2.8951684317053363, 0.14327866527492794, 0.43214024606770957)\n",
      "iter:388, loss:3.47058734305\n",
      "(2.867300395269702, 0.14358030291464241, 0.43314023929566398)\n",
      "iter:389, loss:3.44402093748\n",
      "(2.8396998095837058, 0.14388200319503897, 0.43414023251182154)\n",
      "iter:390, loss:3.41772204529\n",
      "(2.8123641336071183, 0.1441837657228377, 0.43514022571607036)\n",
      "iter:391, loss:3.39168812505\n",
      "(2.7852908498536189, 0.14448559010796244, 0.43614021890829657)\n",
      "iter:392, loss:3.36591665887\n",
      "(2.7584774641846108, 0.14478747596350913, 0.43714021208838444)\n",
      "iter:393, loss:3.34040515224\n",
      "(2.7319215056046739, 0.1450894229057145, 0.43814020525621622)\n",
      "iter:394, loss:3.31515113377\n",
      "(2.7056205260584876, 0.14539143055392492, 0.43914019841167218)\n",
      "iter:395, loss:3.29015215502\n",
      "(2.6795721002293633, 0.14569349853056587, 0.44014019155463036)\n",
      "iter:396, loss:3.26540579031\n",
      "(2.6537738253392886, 0.14599562646111167, 0.44114018468496713)\n",
      "iter:397, loss:3.24090963649\n",
      "(2.6282233209504939, 0.14629781397405534, 0.44214017780255643)\n",
      "iter:398, loss:3.21666131273\n",
      "(2.6029182287685764, 0.14660006070087919, 0.4431401709072702)\n",
      "iter:399, loss:3.19265846038\n",
      "(2.5778562124471089, 0.14690236627602546, 0.44414016399897832)\n",
      "iter:400, loss:3.16889874272\n",
      "(2.5530349573937787, 0.14720473033686735, 0.44514015707754812)\n",
      "iter:401, loss:3.14537984481\n",
      "(2.5284521705780221, 0.14750715252368057, 0.44614015014284503)\n",
      "iter:402, loss:3.12209947324\n",
      "(2.5041055803401671, 0.14780963247961482, 0.44714014319473228)\n",
      "iter:403, loss:3.09905535601\n",
      "(2.4799929362020348, 0.14811216985066597, 0.44814013623307042)\n",
      "iter:404, loss:3.07624524229\n",
      "(2.4561120086790629, 0.14841476428564834, 0.44914012925771801)\n",
      "iter:405, loss:3.05366690222\n",
      "(2.4324605890938678, 0.14871741543616757, 0.45014012226853101)\n",
      "iter:406, loss:3.0313181268\n",
      "(2.4090364893912843, 0.1490201229565932, 0.45114011526536307)\n",
      "iter:407, loss:3.00919672761\n",
      "(2.3858375419548752, 0.14932288650403233, 0.45214010824806516)\n",
      "iter:408, loss:2.98730053671\n",
      "(2.362861599424869, 0.149625705738303, 0.45314010121648618)\n",
      "iter:409, loss:2.96562740638\n",
      "(2.3401065345175689, 0.14992858032190806, 0.45414009417047219)\n",
      "iter:410, loss:2.94417520901\n",
      "(2.3175702398461535, 0.15023150992000944, 0.45514008710986653)\n",
      "iter:411, loss:2.92294183688\n",
      "(2.2952506277429539, 0.15053449420040255, 0.45614008003451023)\n",
      "iter:412, loss:2.90192520198\n",
      "(2.2731456300831172, 0.15083753283349091, 0.4571400729442413)\n",
      "iter:413, loss:2.88112323586\n",
      "(2.2512531981096839, 0.15114062549226143, 0.45814006583889538)\n",
      "iter:414, loss:2.86053388944\n",
      "(2.2295713022600929, 0.15144377185225943, 0.4591400587183051)\n",
      "iter:415, loss:2.84015513283\n",
      "(2.2080979319940437, 0.15174697159156447, 0.46014005158230031)\n",
      "iter:416, loss:2.81998495517\n",
      "(2.1868310956227814, 0.15205022439076593, 0.461140044430708)\n",
      "iter:417, loss:2.80002136444\n",
      "(2.1657688201397396, 0.15235352993293944, 0.46214003726335229)\n",
      "iter:418, loss:2.78026238734\n",
      "(2.1449091510525542, 0.15265688790362292, 0.46314003008005433)\n",
      "iter:419, loss:2.76070606904\n",
      "(2.1242501522164603, 0.1529602979907935, 0.464140022880632)\n",
      "iter:420, loss:2.74135047309\n",
      "(2.1037899056690263, 0.15326375988484428, 0.46514001566490037)\n",
      "iter:421, loss:2.72219368122\n",
      "(2.0835265114662307, 0.15356727327856148, 0.46614000843267134)\n",
      "iter:422, loss:2.70323379318\n",
      "(2.0634580875198973, 0.15387083786710193, 0.46714000118375343)\n",
      "iter:423, loss:2.68446892657\n",
      "(2.0435827694364419, 0.15417445334797064, 0.46813999391795219)\n",
      "iter:424, loss:2.6658972167\n",
      "(2.0238987103569639, 0.15447811942099868, 0.46913998663506951)\n",
      "iter:425, loss:2.64751681641\n",
      "(2.0044040807986208, 0.1547818357883215, 0.47013997933490415)\n",
      "iter:426, loss:2.62932589592\n",
      "(1.9850970684973388, 0.15508560215435704, 0.4711399720172515)\n",
      "iter:427, loss:2.61132264267\n",
      "(1.9659758782518124, 0.15538941822578456, 0.47213996468190295)\n",
      "iter:428, loss:2.59350526116\n",
      "(1.9470387317687776, 0.15569328371152336, 0.473139957328647)\n",
      "iter:429, loss:2.57587197281\n",
      "(1.928283867509595, 0.15599719832271197, 0.47413994995726799)\n",
      "iter:430, loss:2.55842101579\n",
      "(1.9097095405380835, 0.15630116177268738, 0.47513994256754677)\n",
      "iter:431, loss:2.54115064488\n",
      "(1.8913140223696379, 0.15660517377696453, 0.4761399351592604)\n",
      "iter:432, loss:2.52405913131\n",
      "(1.8730956008215853, 0.15690923405321616, 0.47713992773218206)\n",
      "iter:433, loss:2.50714476261\n",
      "(1.8550525798648017, 0.15721334232125281, 0.47813992028608099)\n",
      "iter:434, loss:2.49040584247\n",
      "(1.8371832794765715, 0.15751749830300274, 0.47913991282072232)\n",
      "iter:435, loss:2.4738406906\n",
      "(1.819486035494672, 0.15782170172249277, 0.48013990533586715)\n",
      "iter:436, loss:2.45744764255\n",
      "(1.8019591994726962, 0.15812595230582846, 0.48113989783127276)\n",
      "iter:437, loss:2.44122504961\n",
      "(1.7846011385365705, 0.15843024978117523, 0.48213989030669152)\n",
      "iter:438, loss:2.42517127862\n",
      "(1.7674102352422978, 0.15873459387873923, 0.48313988276187197)\n",
      "iter:439, loss:2.40928471188\n",
      "(1.7503848874349055, 0.15903898433074859, 0.48413987519655799)\n",
      "iter:440, loss:2.39356374696\n",
      "(1.7335235081085509, 0.15934342087143494, 0.48513986761048922)\n",
      "iter:441, loss:2.37800679659\n",
      "(1.7168245252678813, 0.15964790323701494, 0.48613986000340026)\n",
      "iter:442, loss:2.36261228851\n",
      "(1.7002863817904723, 0.15995243116567212, 0.48713985237502133)\n",
      "iter:443, loss:2.34737866533\n",
      "(1.6839075352905333, 0.16025700439753893, 0.4881398447250776)\n",
      "iter:444, loss:2.33230438441\n",
      "(1.667686457983687, 0.16056162267467891, 0.48913983705328995)\n",
      "iter:445, loss:2.31738791771\n",
      "(1.6516216365529797, 0.16086628574106912, 0.49013982935937328)\n",
      "iter:446, loss:2.30262775165\n",
      "(1.6357115720159596, 0.16117099334258278, 0.49113982164303815)\n",
      "iter:447, loss:2.288022387\n",
      "(1.619954779592959, 0.16147574522697175, 0.49213981390398981)\n",
      "iter:448, loss:2.27357033872\n",
      "(1.6043497885764457, 0.16178054114385002, 0.49313980614192776)\n",
      "iter:449, loss:2.25927013586\n",
      "(1.5888951422015432, 0.16208538084467616, 0.49413979835654653)\n",
      "iter:450, loss:2.2451203214\n",
      "(1.5735893975176254, 0.16239026408273732, 0.49513979054753482)\n",
      "iter:451, loss:2.23111945215\n",
      "(1.5584311252610388, 0.16269519061313209, 0.49613978271457582)\n",
      "iter:452, loss:2.21726609859\n",
      "(1.5434189097289097, 0.16300016019275454, 0.49713977485734678)\n",
      "iter:453, loss:2.20355884478\n",
      "(1.5285513486540541, 0.16330517258027794, 0.49813976697551915)\n",
      "iter:454, loss:2.18999628821\n",
      "(1.5138270530809357, 0.16361022753613874, 0.49913975906875829)\n",
      "iter:455, loss:2.17657703969\n",
      "(1.4992446472427334, 0.16391532482252077, 0.50013975113672327)\n",
      "iter:456, loss:2.1632997232\n",
      "(1.4848027684394518, 0.16422046420333947, 0.50113974317906684)\n",
      "iter:457, loss:2.15016297582\n",
      "(1.4705000669170971, 0.16452564544422643, 0.5021397351954352)\n",
      "iter:458, loss:2.13716544756\n",
      "(1.4563352057478933, 0.16483086831251414, 0.50313972718546862)\n",
      "iter:459, loss:2.12430580125\n",
      "(1.4423068607115586, 0.16513613257722062, 0.50413971914879963)\n",
      "iter:460, loss:2.11158271244\n",
      "(1.4284137201775871, 0.16544143800903444, 0.50513971108505429)\n",
      "iter:461, loss:2.09899486927\n",
      "(1.4146544849885867, 0.16574678438029994, 0.50613970299385191)\n",
      "iter:462, loss:2.08654097236\n",
      "(1.4010278683446034, 0.1660521714650024, 0.50713969487480381)\n",
      "iter:463, loss:2.07421973468\n",
      "(1.3875325956885005, 0.16635759903875338, 0.50813968672751431)\n",
      "iter:464, loss:2.06202988145\n",
      "(1.3741674045922894, 0.16666306687877658, 0.50913967855158049)\n",
      "iter:465, loss:2.04997015002\n",
      "(1.3609310446444955, 0.16696857476389318, 0.51013967034659125)\n",
      "iter:466, loss:2.03803928975\n",
      "(1.3478222773384951, 0.16727412247450804, 0.51113966211212736)\n",
      "iter:467, loss:2.02623606193\n",
      "(1.3348398759618274, 0.16757970979259548, 0.51213965384776194)\n",
      "iter:468, loss:2.0145592396\n",
      "(1.3219826254865119, 0.16788533650168552, 0.51313964555305946)\n",
      "iter:469, loss:2.00300760754\n",
      "(1.3092493224602779, 0.16819100238685014, 0.51413963722757605)\n",
      "iter:470, loss:1.99157996207\n",
      "(1.2966387748988066, 0.16849670723468979, 0.51513962887085896)\n",
      "iter:471, loss:1.980275111\n",
      "(1.2841498021788913, 0.16880245083331985, 0.51613962048244688)\n",
      "iter:472, loss:1.96909187349\n",
      "(1.2717812349325468, 0.16910823297235733, 0.51713961206186876)\n",
      "iter:473, loss:1.95802907997\n",
      "(1.259531914942065, 0.16941405344290783, 0.51813960360864442)\n",
      "iter:474, loss:1.94708557199\n",
      "(1.2474006950359899, 0.16971991203755232, 0.51913959512228425)\n",
      "iter:475, loss:1.9362602022\n",
      "(1.2353864389860232, 0.17002580855033442, 0.52013958660228854)\n",
      "iter:476, loss:1.92555183414\n",
      "(1.2234880214048351, 0.17033174277674745, 0.52113957804814759)\n",
      "iter:477, loss:1.91495934223\n",
      "(1.2117043276447879, 0.17063771451372192, 0.52213956945934104)\n",
      "iter:478, loss:1.90448161162\n",
      "(1.2000342536975621, 0.17094372355961296, 0.52313956083533875)\n",
      "iter:479, loss:1.89411753809\n",
      "(1.1884767060946686, 0.17124976971418782, 0.5241395521755986)\n",
      "iter:480, loss:1.88386602798\n",
      "(1.177030601808867, 0.17155585277861382, 0.52513954347956815)\n",
      "iter:481, loss:1.87372599807\n",
      "(1.1656948681564221, 0.17186197255544586, 0.52613953474668285)\n",
      "iter:482, loss:1.86369637546\n",
      "(1.1544684427002849, 0.17216812884861477, 0.52713952597636726)\n",
      "iter:483, loss:1.85377609753\n",
      "(1.1433502731541056, 0.17247432146341501, 0.52813951716803254)\n",
      "iter:484, loss:1.84396411179\n",
      "(1.1323393172871008, 0.17278055020649319, 0.52913950832107892)\n",
      "iter:485, loss:1.83425937581\n",
      "(1.12143454282981, 0.17308681488583613, 0.53013949943489314)\n",
      "iter:486, loss:1.82466085715\n",
      "(1.1106349273806462, 0.17339311531075946, 0.5311394905088489)\n",
      "iter:487, loss:1.8151675332\n",
      "(1.0999394583133273, 0.17369945129189601, 0.53213948154230639)\n",
      "iter:488, loss:1.80577839115\n",
      "(1.0893471326851132, 0.1740058226411845, 0.53313947253461291)\n",
      "iter:489, loss:1.79649242786\n",
      "(1.0788569571458864, 0.17431222917185843, 0.53413946348510044)\n",
      "iter:490, loss:1.7873086498\n",
      "(1.0684679478480306, 0.17461867069843473, 0.53513945439308719)\n",
      "iter:491, loss:1.77822607294\n",
      "(1.0581791303571357, 0.17492514703670275, 0.53613944525787638)\n",
      "iter:492, loss:1.76924372265\n",
      "(1.0479895395635055, 0.17523165800371357, 0.53713943607875558)\n",
      "iter:493, loss:1.76036063365\n",
      "(1.0378982195944531, 0.17553820341776885, 0.53813942685499683)\n",
      "iter:494, loss:1.75157584987\n",
      "(1.0279042237274032, 0.17584478309841034, 0.53913941758585615)\n",
      "iter:495, loss:1.74288842441\n",
      "(1.0180066143037818, 0.17615139686640907, 0.54013940827057272)\n",
      "iter:496, loss:1.73429741944\n",
      "(1.0082044626436495, 0.17645804454375502, 0.54113939890836826)\n",
      "iter:497, loss:1.7258019061\n",
      "(0.99849684896115876, 0.17676472595364656, 0.54213938949844742)\n",
      "iter:498, loss:1.71740096441\n",
      "(0.98888286228073796, 0.17707144092048011, 0.54313938003999651)\n",
      "iter:499, loss:1.70909368324\n",
      "(0.97936160035405984, 0.17737818926983995, 0.54413937053218331)\n",
      "iter:500, loss:1.70087916016\n",
      "(0.96993216957774764, 0.17768497082848811, 0.54513936097415605)\n",
      "iter:501, loss:1.69275650138\n",
      "(0.96059368491182839, 0.1779917854243542, 0.54613935136504355)\n",
      "iter:502, loss:1.6847248217\n",
      "(0.95134526979894285, 0.17829863288652559, 0.54713934170395417)\n",
      "iter:503, loss:1.67678324439\n",
      "(0.94218605608427874, 0.17860551304523734, 0.54813933198997544)\n",
      "iter:504, loss:1.66893090112\n",
      "(0.93311518393622939, 0.17891242573186272, 0.5491393222221731)\n",
      "iter:505, loss:1.66116693189\n",
      "(0.92413180176778575, 0.17921937077890315, 0.55013931239959091)\n",
      "iter:506, loss:1.65349048495\n",
      "(0.91523506615864336, 0.17952634801997885, 0.55113930252124943)\n",
      "iter:507, loss:1.6459007167\n",
      "(0.90642414177800179, 0.1798333572898192, 0.55213929258614614)\n",
      "iter:508, loss:1.63839679165\n",
      "(0.89769820130809985, 0.18014039842425333, 0.5531392825932534)\n",
      "iter:509, loss:1.63097788233\n",
      "(0.88905642536842833, 0.18044747126020072, 0.55413927254151929)\n",
      "iter:510, loss:1.62364316917\n",
      "(0.88049800244063869, 0.18075457563566188, 0.55513926242986555)\n",
      "iter:511, loss:1.61639184051\n",
      "(0.87202212879414154, 0.18106171138970933, 0.55613925225718763)\n",
      "iter:512, loss:1.60922309244\n",
      "(0.8636280084123884, 0.18136887836247817, 0.55713924202235277)\n",
      "iter:513, loss:1.6021361288\n",
      "(0.8553148529198229, 0.18167607639515723, 0.55813923172420044)\n",
      "iter:514, loss:1.59513016104\n",
      "(0.84708188150951358, 0.18198330532998006, 0.55913922136154071)\n",
      "iter:515, loss:1.5882044082\n",
      "(0.83892832087143343, 0.18229056501021598, 0.56013921093315322)\n",
      "iter:516, loss:1.58135809681\n",
      "(0.83085340512141581, 0.18259785528016118, 0.5611392004377862)\n",
      "iter:517, loss:1.57459046084\n",
      "(0.82285637573074666, 0.18290517598513015, 0.56213918987415601)\n",
      "iter:518, loss:1.56790074159\n",
      "(0.81493648145641751, 0.18321252697144674, 0.56313917924094559)\n",
      "iter:519, loss:1.56128818767\n",
      "(0.80709297827201631, 0.1835199080864357, 0.56413916853680302)\n",
      "iter:520, loss:1.5547520549\n",
      "(0.79932512929925148, 0.18382731917841394, 0.56513915776034107)\n",
      "iter:521, loss:1.54829160624\n",
      "(0.79163220474010632, 0.18413476009668223, 0.56613914691013578)\n",
      "iter:522, loss:1.54190611175\n",
      "(0.7840134818096286, 0.18444223069151655, 0.56713913598472487)\n",
      "iter:523, loss:1.53559484849\n",
      "(0.77646824466932374, 0.18474973081415991, 0.56813912498260688)\n",
      "iter:524, loss:1.52935710047\n",
      "(0.76899578436118032, 0.1850572603168138, 0.56913911390223915)\n",
      "iter:525, loss:1.52319215858\n",
      "(0.76159539874228854, 0.18536481905263003, 0.57013910274203727)\n",
      "iter:526, loss:1.51709932054\n",
      "(0.75426639242008264, 0.18567240687570255, 0.57113909150037312)\n",
      "iter:527, loss:1.5110778908\n",
      "(0.7470080766881565, 0.18598002364105928, 0.57213908017557336)\n",
      "iter:528, loss:1.5051271805\n",
      "(0.739819769462704, 0.18628766920465389, 0.57313906876591758)\n",
      "iter:529, loss:1.49924650743\n",
      "(0.73270079521951237, 0.18659534342335787, 0.5741390572696371)\n",
      "iter:530, loss:1.49343519591\n",
      "(0.72565048493157536, 0.1869030461549524, 0.57513904568491248)\n",
      "iter:531, loss:1.48769257677\n",
      "(0.71866817600725841, 0.18721077725812044, 0.57613903400987299)\n",
      "iter:532, loss:1.48201798728\n",
      "(0.71175321222904486, 0.18751853659243886, 0.57713902224259295)\n",
      "iter:533, loss:1.47641077106\n",
      "(0.70490494369286472, 0.18782632401837041, 0.57813901038109128)\n",
      "iter:534, loss:1.47087027809\n",
      "(0.6981227267479575, 0.18813413939725598, 0.57913899842332828)\n",
      "iter:535, loss:1.46539586457\n",
      "(0.69140592393732092, 0.18844198259130682, 0.58013898636720396)\n",
      "iter:536, loss:1.4599868929\n",
      "(0.6847539039387085, 0.18874985346359663, 0.58113897421055594)\n",
      "iter:537, loss:1.45464273161\n",
      "(0.67816604150615412, 0.1890577518780539, 0.58213896195115633)\n",
      "iter:538, loss:1.44936275534\n",
      "(0.67164171741207102, 0.18936567769945431, 0.58313894958670964)\n",
      "iter:539, loss:1.4441463447\n",
      "(0.66518031838987035, 0.18967363079341271, 0.58413893711485032)\n",
      "iter:540, loss:1.4389928863\n",
      "(0.65878123707712721, 0.18998161102637587, 0.58513892453313943)\n",
      "iter:541, loss:1.43390177264\n",
      "(0.65244387195925546, 0.19028961826561441, 0.58613891183906264)\n",
      "iter:542, loss:1.42887240206\n",
      "(0.64616762731374022, 0.19059765237921561, 0.58713889903002581)\n",
      "iter:543, loss:1.42390417872\n",
      "(0.639951913154856, 0.19090571323607541, 0.58813888610335296)\n",
      "iter:544, loss:1.41899651249\n",
      "(0.63379614517892602, 0.191213800705891, 0.58913887305628276)\n",
      "iter:545, loss:1.41414881894\n",
      "(0.6276997447100876, 0.1915219146591533, 0.59013885988596393)\n",
      "iter:546, loss:1.40936051926\n",
      "(0.62166213864655306, 0.19183005496713909, 0.59113884658945293)\n",
      "iter:547, loss:1.4046310402\n",
      "(0.61568275940738781, 0.19213822150190366, 0.5921388331637093)\n",
      "iter:548, loss:1.39995981407\n",
      "(0.60976104487977756, 0.19244641413627317, 0.59313881960559178)\n",
      "iter:549, loss:1.39534627862\n",
      "(0.60389643836679174, 0.19275463274383686, 0.59413880591185353)\n",
      "iter:550, loss:1.39078987702\n",
      "(0.59808838853563873, 0.19306287719893978, 0.59513879207913822)\n",
      "iter:551, loss:1.38629005781\n",
      "(0.59233634936640056, 0.19337114737667466, 0.59613877810397475)\n",
      "iter:552, loss:1.38184627485\n",
      "(0.58663978010125462, 0.19367944315287466, 0.59713876398277255)\n",
      "iter:553, loss:1.37745798724\n",
      "(0.58099814519416526, 0.19398776440410548, 0.59813874971181569)\n",
      "iter:554, loss:1.37312465931\n",
      "(0.57541091426105584, 0.19429611100765767, 0.59913873528725847)\n",
      "iter:555, loss:1.36884576056\n",
      "(0.56987756203043516, 0.1946044828415387, 0.60013872070511753)\n",
      "iter:556, loss:1.36462076558\n",
      "(0.56439756829450571, 0.19491287978446536, 0.60113870596126739)\n",
      "iter:557, loss:1.36044915404\n",
      "(0.55897041786072266, 0.19522130171585567, 0.60213869105143314)\n",
      "iter:558, loss:1.35633041063\n",
      "(0.55359560050379519, 0.19552974851582103, 0.6031386759711832)\n",
      "iter:559, loss:1.35226402499\n",
      "(0.5482726109181727, 0.19583822006515808, 0.60413866071592226)\n",
      "iter:560, loss:1.3482494917\n",
      "(0.5430009486709424, 0.19614671624534069, 0.60513864528088324)\n",
      "iter:561, loss:1.3442863102\n",
      "(0.53778011815519366, 0.19645523693851163, 0.60613862966111931)\n",
      "iter:562, loss:1.34037398475\n",
      "(0.53260962854381899, 0.19676378202747441, 0.60713861385149448)\n",
      "iter:563, loss:1.33651202442\n",
      "(0.52748899374373182, 0.19707235139568455, 0.60813859784667534)\n",
      "iter:564, loss:1.33269994299\n",
      "(0.52241773235055955, 0.19738094492724129, 0.60913858164111978)\n",
      "iter:565, loss:1.32893725892\n",
      "(0.51739536760370697, 0.19768956250687872, 0.61013856522906762)\n",
      "iter:566, loss:1.32522349534\n",
      "(0.51242142734189222, 0.19799820401995691, 0.61113854860452921)\n",
      "iter:567, loss:1.32155817997\n",
      "(0.50749544395908674, 0.19830686935245301, 0.61213853176127331)\n",
      "iter:568, loss:1.31794084507\n",
      "(0.50261695436085618, 0.19861555839095174, 0.61313851469281444)\n",
      "iter:569, loss:1.31437102744\n",
      "(0.49778549992114662, 0.19892427102263621, 0.61413849739240012)\n",
      "iter:570, loss:1.31084826834\n",
      "(0.49300062643945153, 0.19923300713527803, 0.61513847985299597)\n",
      "iter:571, loss:1.30737211343\n",
      "(0.4882618840984056, 0.1995417666172275, 0.61613846206727096)\n",
      "iter:572, loss:1.30394211278\n",
      "(0.48356882742176366, 0.19985054935740337, 0.61713844402758034)\n",
      "iter:573, loss:1.30055782081\n",
      "(0.47892101523279684, 0.20015935524528225, 0.61813842572594979)\n",
      "iter:574, loss:1.2972187962\n",
      "(0.4743180106130675, 0.20046818417088796, 0.61913840715405544)\n",
      "iter:575, loss:1.29392460194\n",
      "(0.46975938086160646, 0.20077703602478017, 0.62013838830320522)\n",
      "iter:576, loss:1.29067480519\n",
      "(0.46524469745448754, 0.20108591069804277, 0.62113836916431708)\n",
      "iter:577, loss:1.28746897732\n",
      "(0.46077353600475329, 0.20139480808227195, 0.62213834972789694)\n",
      "iter:578, loss:1.28430669381\n",
      "(0.45634547622277649, 0.20170372806956363, 0.62313832998401331)\n",
      "iter:579, loss:1.28118753428\n",
      "(0.45196010187694308, 0.20201267055250061, 0.62413830992227326)\n",
      "iter:580, loss:1.27811108235\n",
      "(0.44761700075476446, 0.20232163542413867, 0.62513828953179251)\n",
      "iter:581, loss:1.27507692571\n",
      "(0.44331576462432148, 0.20263062257799269, 0.62613826880116674)\n",
      "iter:582, loss:1.272084656\n",
      "(0.439055989196103, 0.20293963190802158, 0.62713824771843896)\n",
      "iter:583, loss:1.26913386882\n",
      "(0.43483727408519945, 0.20324866330861271, 0.62813822627106486)\n",
      "iter:584, loss:1.26622416366\n",
      "(0.43065922277386542, 0.20355771667456557, 0.62913820444587587)\n",
      "iter:585, loss:1.26335514389\n",
      "(0.42652144257444718, 0.20386679190107412, 0.63013818222903772)\n",
      "iter:586, loss:1.2605264167\n",
      "(0.42242354459265719, 0.20417588888370899, 0.63113815960600883)\n",
      "iter:587, loss:1.25773759308\n",
      "(0.41836514369121808, 0.20448500751839768, 0.63213813656149209)\n",
      "iter:588, loss:1.25498828777\n",
      "(0.41434585845384836, 0.20479414770140406, 0.63313811307938361)\n",
      "iter:589, loss:1.25227811923\n",
      "(0.41036531114961267, 0.20510330932930665, 0.63413808914271952)\n",
      "iter:590, loss:1.24960670962\n",
      "(0.40642312769759964, 0.20541249229897518, 0.635138064733615)\n",
      "iter:591, loss:1.24697368473\n",
      "(0.4025189376319771, 0.20572169650754552, 0.63613803983319961)\n",
      "iter:592, loss:1.24437867397\n",
      "(0.39865237406735105, 0.20603092185239344, 0.63713801442154772)\n",
      "iter:593, loss:1.24182131034\n",
      "(0.3948230736645143, 0.20634016823110546, 0.63813798847760195)\n",
      "iter:594, loss:1.23930123037\n",
      "(0.39103067659649343, 0.2066494355414486, 0.63913796197908923)\n",
      "iter:595, loss:1.23681807412\n",
      "(0.38727482651495543, 0.20695872368133683, 0.64013793490243032)\n",
      "iter:596, loss:1.2343714851\n",
      "(0.38355517051695592, 0.20726803254879544, 0.64113790722264152)\n",
      "iter:597, loss:1.23196111029\n",
      "(0.3798713591120087, 0.20757736204192234, 0.64213787891322394)\n",
      "iter:598, loss:1.22958660007\n",
      "(0.37622304618951025, 0.20788671205884582, 0.64313784994604772)\n",
      "iter:599, loss:1.22724760819\n",
      "(0.37260988898647424, 0.20819608249767915, 0.64413782029121924)\n",
      "iter:600, loss:1.22494379178\n",
      "(0.36903154805562427, 0.20850547325647054, 0.64513778991693893)\n",
      "iter:601, loss:1.22267481123\n",
      "(0.36548768723380742, 0.20881488423314887, 0.64613775878934399)\n",
      "iter:602, loss:1.22044033026\n",
      "(0.36197797361075512, 0.20912431532546427, 0.64713772687233473)\n",
      "iter:603, loss:1.21824001581\n",
      "(0.35850207749816054, 0.20943376643092262, 0.64813769412738276)\n",
      "iter:604, loss:1.21607353806\n",
      "(0.35505967239911601, 0.20974323744671414, 0.64913766051331978)\n",
      "iter:605, loss:1.21394057036\n",
      "(0.35165043497788184, 0.21005272826963389, 0.65013762598610236)\n",
      "iter:606, loss:1.21184078923\n",
      "(0.34827404502998627, 0.21036223879599467, 0.65113759049855169)\n",
      "iter:607, loss:1.20977387432\n",
      "(0.34493018545270315, 0.21067176892153025, 0.65213755400006501)\n",
      "iter:608, loss:1.20773950837\n",
      "(0.34161854221584276, 0.21098131854128788, 0.65313751643629203)\n",
      "iter:609, loss:1.20573737719\n",
      "(0.33833880433294067, 0.21129088754950881, 0.65413747774877562)\n",
      "iter:610, loss:1.20376716963\n",
      "(0.33509066383277669, 0.21160047583949515, 0.65513743787454826)\n",
      "iter:611, loss:1.20182857755\n",
      "(0.3318738157313032, 0.21191008330346045, 0.65613739674568128)\n",
      "iter:612, loss:1.19992129578\n",
      "(0.32868795800392747, 0.21221970983236266, 0.65713735428877673)\n",
      "iter:613, loss:1.19804502213\n",
      "(0.32553279155822751, 0.21252935531571607, 0.65813731042439494)\n",
      "iter:614, loss:1.1961994573\n",
      "(0.32240802020705961, 0.21283901964137902, 0.65913726506640924)\n",
      "iter:615, loss:1.19438430491\n",
      "(0.31931335064211974, 0.21314870269531419, 0.66013721812127368)\n",
      "iter:616, loss:1.19259927146\n",
      "(0.3162484924079601, 0.21345840436131625, 0.66113716948719203)\n",
      "iter:617, loss:1.19084406626\n",
      "(0.31321315787650017, 0.21376812452070229, 0.66213711905317152)\n",
      "iter:618, loss:1.18911840145\n",
      "(0.31020706222206834, 0.21407786305195795, 0.66313706669794081)\n",
      "iter:619, loss:1.18742199197\n",
      "(0.30722992339700772, 0.21438761983033242, 0.66413701228871203)\n",
      "iter:620, loss:1.18575455552\n",
      "(0.3042814621079149, 0.21469739472737284, 0.66513695567975439)\n",
      "iter:621, loss:1.18411581252\n",
      "(0.3013614017925581, 0.21500718761038662, 0.66613689671075105)\n",
      "iter:622, loss:1.18250548611\n",
      "(0.2984694685975704, 0.21531699834181919, 0.66713683520489453)\n",
      "iter:623, loss:1.18092330214\n",
      "(0.2956053913569926, 0.21562682677853015, 0.66813677096667323)\n",
      "iter:624, loss:1.1793689891\n",
      "(0.29276890157181357, 0.21593667277094775, 0.66913670377928725)\n",
      "iter:625, loss:1.17784227812\n",
      "(0.28995973339061637, 0.21624653616207748, 0.67013663340161811)\n",
      "iter:626, loss:1.17634290295\n",
      "(0.28717762359155147, 0.21655641678633308, 0.67113655956466156)\n",
      "iter:627, loss:1.17487059994\n",
      "(0.28442231156583864, 0.2168663144681523, 0.67213648196730524)\n",
      "iter:628, loss:1.173425108\n",
      "(0.28169353930309021, 0.21717622902034861, 0.67313640027130428)\n",
      "iter:629, loss:1.17200616859\n",
      "(0.27899105137882524, 0.21748616024213752, 0.67413631409527608)\n",
      "iter:630, loss:1.17061352572\n",
      "(0.27631459494462096, 0.21779610791675938, 0.67513622300747211)\n",
      "iter:631, loss:1.16924692587\n",
      "(0.27366391972153614, 0.21810607180859784, 0.67613612651703026)\n",
      "iter:632, loss:1.16790611805\n",
      "(0.27103877799752468, 0.21841605165966305, 0.67713602406331519)\n",
      "iter:633, loss:1.16659085372\n",
      "(0.26843892462989705, 0.21872604718526834, 0.6781359150028341)\n",
      "iter:634, loss:1.16530088682\n",
      "(0.26586411705415042, 0.21903605806867385, 0.67913579859305473)\n",
      "iter:635, loss:1.16403597372\n",
      "(0.2633141153009394, 0.21934608395439237, 0.68013567397222252)\n",
      "iter:636, loss:1.16279587323\n",
      "(0.26078868202364336, 0.21965612443974841, 0.68113554013396194)\n",
      "iter:637, loss:1.1615803466\n",
      "(0.25828758253977047, 0.21996617906412563, 0.68213539589499395)\n",
      "iter:638, loss:1.1603891575\n",
      "(0.25581058489082104, 0.22027624729511963, 0.68313523985366409)\n",
      "iter:639, loss:1.15922207204\n",
      "(0.25335745992707742, 0.22058632851049112, 0.68413507033602983)\n",
      "iter:640, loss:1.15807885877\n",
      "(0.25092798142647194, 0.22089642197433057, 0.68513488532485545)\n",
      "iter:641, loss:1.15695928873\n",
      "(0.2485219262610926, 0.22120652680511235, 0.68613468236473141)\n",
      "iter:642, loss:1.15586313543\n",
      "(0.24613907463131268, 0.22151664193216833, 0.6871344584332163)\n",
      "iter:643, loss:1.154790175\n",
      "(0.24377921039810072, 0.22182676603527496, 0.68813420976261819)\n",
      "iter:644, loss:1.1537401862\n",
      "(0.24144212156135259, 0.22213689745902068, 0.68913393158833447)\n",
      "iter:645, loss:1.15271295061\n",
      "(0.23912760096124258, 0.22244703408846356, 0.69013361778494209)\n",
      "iter:646, loss:1.15170825283\n",
      "(0.23683544733134942, 0.22275717316345434, 0.69113326032522593)\n",
      "iter:647, loss:1.15072588082\n",
      "(0.23456546692734109, 0.22306731099209284, 0.69213284844941936)\n",
      "iter:648, loss:1.14976562637\n",
      "(0.23231747614007159, 0.22337744249075825, 0.69313236733879136)\n",
      "iter:649, loss:1.14882728597\n",
      "(0.23009130588506729, 0.22368756040940416, 0.69413179589471952)\n",
      "iter:650, loss:1.14791066219\n",
      "(0.22788680941952713, 0.2239976539459021, 0.6951311027917656)\n",
      "iter:651, loss:1.14701556616\n",
      "(0.22570387736547892, 0.2243077060675614, 0.69613023890171011)\n",
      "iter:652, loss:1.14614182233\n",
      "(0.22354246972157299, 0.22461768776386493, 0.69712912116139092)\n",
      "iter:653, loss:1.14528927865\n",
      "(0.22140269490024334, 0.22492754374376447, 0.69812759275335701)\n",
      "iter:654, loss:1.1444578314\n",
      "(0.21928505450687882, 0.22523714776066506, 0.69912529978051352)\n",
      "iter:655, loss:1.14364750205\n",
      "(0.21719156550814434, 0.22554609604925516, 0.70012112568234863)\n",
      "iter:656, loss:1.14285878724\n",
      "(0.21513777584773641, 0.22585147904951267, 0.70110712864956781)\n",
      "iter:657, loss:1.14209638355\n",
      "(0.21341146223790713, 0.22609958947924752, 0.70193725969544374)\n",
      "iter:658, loss:1.14144831141\n",
      "(0.21177888715728513, 0.22633314752164685, 0.70272684143960695)\n",
      "iter:659, loss:1.14083887612\n",
      "(0.2104103774083011, 0.22652423955846551, 0.703389669054997)\n",
      "iter:660, loss:1.14032428602\n",
      "(0.2095658745686704, 0.22662322211434427, 0.70379270615052636)\n",
      "iter:661, loss:1.13998180283\n",
      "(0.20911157607216199, 0.2266555092476816, 0.70400101564582684)\n",
      "iter:662, loss:1.13976810097\n",
      "(0.20873728532059968, 0.22667351118639467, 0.70416966488613497)\n",
      "iter:663, loss:1.13958046139\n",
      "(0.20866490794968959, 0.2266330247236415, 0.70418736434124019)\n",
      "iter:664, loss:1.13948529701\n",
      "(0.20862461562477913, 0.22658669806902579, 0.7041890295976686)\n",
      "iter:665, loss:1.13940034329\n",
      "(0.20858726085797971, 0.22654024146862556, 0.70418926261161829)\n",
      "iter:666, loss:1.13931676494\n",
      "(0.20855028918188726, 0.22649415727041183, 0.70418934409132217)\n",
      "iter:667, loss:1.13923379054\n",
      "(0.20851344419074155, 0.22644849626491978, 0.70418940263483454)\n",
      "iter:668, loss:1.13915134309\n",
      "(0.20847669709087766, 0.22640326439827207, 0.70418945266927124)\n",
      "iter:669, loss:1.13906941416\n",
      "(0.20844004299874633, 0.2263584628901818, 0.70418949662321051)\n",
      "iter:670, loss:1.13898800251\n",
      "(0.20840347994488551, 0.22631409238095426, 0.70418953546300811)\n",
      "iter:671, loss:1.13890710779\n",
      "(0.2083670065778446, 0.22627015338648584, 0.70418956984543535)\n",
      "iter:672, loss:1.13882672981\n",
      "(0.20833062184552822, 0.22622664636152889, 0.70418960027755206)\n",
      "iter:673, loss:1.13874686848\n",
      "(0.2082943249067386, 0.22618357171721659, 0.70418962716100841)\n",
      "iter:674, loss:1.13866752378\n",
      "(0.20825811508251371, 0.22614092983068504, 0.70418965081638185)\n",
      "iter:675, loss:1.13858869573\n",
      "(0.20822199182243828, 0.2260987210517402, 0.70418967150001832)\n",
      "iter:676, loss:1.13851038437\n",
      "(0.2081859546801765, 0.22605694570771762, 0.70418968941627258)\n",
      "iter:677, loss:1.1384325898\n",
      "(0.20815000329543726, 0.22601560410707627, 0.70418970472651887)\n",
      "iter:678, loss:1.13835531213\n",
      "(0.20811413738071102, 0.22597469654206681, 0.70418971755578663)\n",
      "iter:679, loss:1.13827855148\n",
      "(0.2080783567115787, 0.22593422329070334, 0.70418972799760393)\n",
      "iter:680, loss:1.138202308\n",
      "(0.20804266111982136, 0.22589418461819766, 0.70418973611743796)\n",
      "iter:681, loss:1.13812658186\n",
      "(0.20800705048882534, 0.225854580777962, 0.70418974195499828)\n",
      "iter:682, loss:1.13805137322\n",
      "(0.2079715247508977, 0.22581541201225164, 0.70418974552557101)\n",
      "iter:683, loss:1.13797668229\n",
      "(0.2079360838863607, 0.22577667855248992, 0.70418974682047764)\n",
      "iter:684, loss:1.13790250926\n",
      "(0.20790072792431386, 0.22573838061929596, 0.70418974580668958)\n",
      "iter:685, loss:1.13782885435\n",
      "(0.20786545694513558, 0.22570051842221292, 0.70418974242557109)\n",
      "iter:686, loss:1.13775571779\n",
      "(0.20783027108493562, 0.2256630921591164, 0.70418973659066031)\n",
      "iter:687, loss:1.13768309983\n",
      "(0.20779517054223343, 0.22562610201525449, 0.70418972818432446)\n",
      "iter:688, loss:1.13761100074\n",
      "(0.20776015558740402, 0.22558954816184498, 0.7041897170530329)\n",
      "iter:689, loss:1.1375394208\n",
      "(0.20772522657565931, 0.22555343075411263, 0.70418970300086448)\n",
      "iter:690, loss:1.13746836033\n",
      "(0.20769038396468553, 0.2255177499285945, 0.70418968578068963)\n",
      "iter:691, loss:1.13739781967\n",
      "(0.20765562833856147, 0.22548250579946005, 0.70418966508220304)\n",
      "iter:692, loss:1.13732779922\n",
      "(0.20762096044041989, 0.22544769845346863, 0.70418964051558852)\n",
      "iter:693, loss:1.13725829941\n",
      "(0.20758638121749529, 0.22541332794299823, 0.70418961158899229)\n",
      "iter:694, loss:1.13718932075\n",
      "(0.20755189188413062, 0.22537939427627954, 0.70418957767700385)\n",
      "iter:695, loss:1.13712086384\n",
      "(0.20751749401153177, 0.22534589740347677, 0.70418953797577766)\n",
      "iter:696, loss:1.13705292939\n",
      "(0.20748318965826021, 0.22531283719643547, 0.70418949143776066)\n",
      "iter:697, loss:1.13698551829\n",
      "(0.20744898156479008, 0.22528021341848481, 0.7041894366743966)\n",
      "iter:698, loss:1.13691863166\n",
      "(0.20741487345198209, 0.22524802567810345, 0.70418937180685237)\n",
      "iter:699, loss:1.13685227094\n",
      "(0.20738087049467568, 0.22521627335539918, 0.7041892942291782)\n",
      "iter:700, loss:1.13678643808\n",
      "(0.20734698010340741, 0.22518495548075013, 0.70418920021735776)\n",
      "iter:701, loss:1.1367211358\n",
      "(0.20731321327706376, 0.22515407052481803, 0.70418908425284799)\n",
      "iter:702, loss:1.13665636805\n",
      "(0.20727958708054764, 0.22512361601392242, 0.70418893778350977)\n",
      "iter:703, loss:1.13659214088\n",
      "(0.20724612951304439, 0.22509358777431265, 0.70418874678900578)\n",
      "iter:704, loss:1.13652846408\n",
      "(0.2072128899605343, 0.22506397830957928, 0.70418848655357125)\n",
      "iter:705, loss:1.13646535482\n",
      "(0.20717996439149497, 0.22503477288938473, 0.70418810906586082)\n",
      "iter:706, loss:1.13640284635\n",
      "(0.20714756646906357, 0.22500593850998396, 0.70418750745645609)\n",
      "iter:707, loss:1.13634101244\n",
      "(0.20711627980642441, 0.22497738473157369, 0.70418638984784176)\n",
      "iter:708, loss:1.13628005439\n",
      "(0.20708834283001162, 0.22494876418089069, 0.70418363681468099)\n",
      "iter:709, loss:1.13622074383\n",
      "(0.20707976014039686, 0.22491759170874903, 0.7041712450203953)\n",
      "iter:710, loss:1.13616859687\n",
      "(0.20711849134046922, 0.22487951267634562, 0.70413523401570166)\n",
      "iter:711, loss:1.13613323803\n",
      "(0.20709334848786554, 0.22485178734225211, 0.70413119256881718)\n",
      "iter:712, loss:1.1360763284\n",
      "(0.20713180297260333, 0.22481460870506551, 0.70409539144919964)\n",
      "iter:713, loss:1.13604180313\n",
      "(0.20710623309659879, 0.22478783326325075, 0.7040916349218409)\n",
      "iter:714, loss:1.13598570128\n",
      "(0.20714361771505632, 0.22475167998016155, 0.70405644012772006)\n",
      "iter:715, loss:1.13595173782\n",
      "(0.20711806102837271, 0.22472578721838407, 0.7040527485567355)\n",
      "iter:716, loss:1.1358965968\n",
      "(0.20716436308079844, 0.22468909867993975, 0.70401316736025121)\n",
      "iter:717, loss:1.13586662912\n",
      "(0.20713962738749167, 0.22466396073585015, 0.7040091362253339)\n",
      "iter:718, loss:1.13581272435\n",
      "(0.20713417638557893, 0.22463624676891103, 0.70399550042933978)\n",
      "iter:719, loss:1.13576592358\n",
      "(0.20721279439799969, 0.22459577028807842, 0.70393987285778714)\n",
      "iter:720, loss:1.13574843754\n",
      "(0.20719001685344243, 0.22457164695516327, 0.70393496814219148)\n",
      "iter:721, loss:1.13569663195\n",
      "(0.20716190937925563, 0.22454881230043219, 0.70393276576064157)\n",
      "iter:722, loss:1.13564348744\n",
      "(0.20717763142367793, 0.22451951804437567, 0.70390868709555865)\n",
      "iter:723, loss:1.13560583656\n",
      "(0.20715072048802693, 0.22449738969588756, 0.70390596010227791)\n",
      "iter:724, loss:1.13555407029\n",
      "(0.2074654294872833, 0.22442177486310541, 0.70373256787236327)\n",
      "iter:725, loss:1.13561977222\n",
      "(0.20744369084473924, 0.22439967159966964, 0.70372731419124035)\n",
      "iter:726, loss:1.13557067664\n",
      "(0.20741266350371326, 0.22437946622825422, 0.70372673041067035)\n",
      "iter:727, loss:1.13551886014\n",
      "(0.2073809961550922, 0.22435981596090968, 0.70372650500530887)\n",
      "iter:728, loss:1.13546731712\n",
      "(0.20734951376690167, 0.2243405925185977, 0.70372622659352713)\n",
      "iter:729, loss:1.13541633288\n",
      "(0.20731838377732695, 0.22432176944763824, 0.70372581149772839)\n",
      "iter:730, loss:1.13536596472\n",
      "(0.20728787043134775, 0.22430330458563522, 0.70372512755529604)\n",
      "iter:731, loss:1.13531630257\n",
      "(0.20725874066874017, 0.22428507534211969, 0.70372379121171547)\n",
      "iter:732, loss:1.13526760722\n",
      "(0.20723426463555947, 0.22426655861909445, 0.70372016711045049)\n",
      "iter:733, loss:1.13522099037\n",
      "(0.2072414415938951, 0.22424343396772925, 0.70370075447512237)\n",
      "iter:734, loss:1.13518563004\n",
      "(0.20721860887574423, 0.22422555295048011, 0.70369638257003531)\n",
      "iter:735, loss:1.1351405444\n",
      "(0.20755331551524459, 0.22415090186639081, 0.7035133987104254)\n",
      "iter:736, loss:1.13521761609\n",
      "(0.20753209898349706, 0.22413360534262894, 0.70350827882098144)\n",
      "iter:737, loss:1.13517398315\n",
      "(0.20750180363831147, 0.22411819189791038, 0.70350772197347577)\n",
      "iter:738, loss:1.13512771751\n",
      "(0.20747085860046685, 0.2241033375975918, 0.70350752804866667)\n",
      "iter:739, loss:1.13508172425\n",
      "(0.20744005325150511, 0.22408891838064587, 0.70350730364355407)\n",
      "iter:740, loss:1.13503627528\n",
      "(0.20740951671552404, 0.22407491364148982, 0.70350698426110014)\n",
      "iter:741, loss:1.13499141462\n",
      "(0.20737940267721364, 0.22406129853207402, 0.70350649303147716)\n",
      "iter:742, loss:1.13494719424\n",
      "(0.20735008917292125, 0.22404801179166009, 0.70350564088635492)\n",
      "iter:743, loss:1.13490374185\n",
      "(0.20732280659458635, 0.22403485385592437, 0.70350381250947502)\n",
      "iter:744, loss:1.13486147296\n",
      "(0.20730397228574382, 0.2240207834058468, 0.70349779873745966)\n",
      "iter:745, loss:1.13482255443\n",
      "(0.20734863927700092, 0.22399686418028095, 0.70346007356847029)\n",
      "iter:746, loss:1.13480557703\n",
      "(0.20732571664055341, 0.22398434762779071, 0.70345617482057055)\n",
      "iter:747, loss:1.13476623909\n",
      "(0.20731883301811527, 0.22396967692906103, 0.70344429420142263)\n",
      "iter:748, loss:1.13473280415\n",
      "(0.20742344121508652, 0.22393730887633653, 0.70337671598295648)\n",
      "iter:749, loss:1.13473746607\n",
      "(0.20740289867866657, 0.22392573511156444, 0.70337173194222802)\n",
      "iter:750, loss:1.13470036573\n",
      "(0.20737474249297339, 0.22391585570264427, 0.7033705908722524)\n",
      "iter:751, loss:1.13466118907\n",
      "(0.20735228458117613, 0.2239055030319857, 0.70336663963694068)\n",
      "iter:752, loss:1.13462442725\n",
      "(0.20737600977832504, 0.22388805027674952, 0.70333963510247732)\n",
      "iter:753, loss:1.13460369516\n",
      "(0.20735137720939295, 0.22387895270808983, 0.70333684387549089)\n",
      "iter:754, loss:1.13456717379\n",
      "(0.20758021819440989, 0.22382878833364198, 0.70320741153209088)\n",
      "iter:755, loss:1.13461641806\n",
      "(0.20756003545759499, 0.22381982012485135, 0.7032024591139675)\n",
      "iter:756, loss:1.1345823147\n",
      "(0.20753120151369561, 0.22381271761689933, 0.703201862233786)\n",
      "iter:757, loss:1.13454578136\n",
      "(0.20750197550116048, 0.22380613770591298, 0.70320149995737113)\n",
      "iter:758, loss:1.13450961316\n",
      "(0.20747325534939351, 0.22379993364503226, 0.70320092397937717)\n",
      "iter:759, loss:1.13447411297\n",
      "(0.20744562286747287, 0.22379400925677884, 0.7031998433568496)\n",
      "iter:760, loss:1.13443947548\n",
      "(0.20742112791603204, 0.22378802537495593, 0.70319723297449555)\n",
      "iter:761, loss:1.13440638627\n",
      "(0.20741323649839116, 0.22377975347896242, 0.70318635901481796)\n",
      "iter:762, loss:1.13437934899\n",
      "(0.20744611363801246, 0.2237651840332322, 0.70315513827432141)\n",
      "iter:763, loss:1.13436643595\n",
      "(0.20742414532820533, 0.22376013451943078, 0.70315137395002825)\n",
      "iter:764, loss:1.1343356538\n",
      "(0.20749177277095573, 0.22374068088239707, 0.70310285391284433)\n",
      "iter:765, loss:1.13433530757\n",
      "(0.20747148509228969, 0.22373624312925133, 0.70309831934053646)\n",
      "iter:766, loss:1.13430604756\n",
      "(0.20744720039686054, 0.22373292501925832, 0.70309582061596609)\n",
      "iter:767, loss:1.13427594603\n",
      "(0.20748446610903989, 0.2237198192884074, 0.70306258598262039)\n",
      "iter:768, loss:1.13426687138\n",
      "(0.20746227419632496, 0.22371705224994454, 0.70305911294555168)\n",
      "iter:769, loss:1.13423843939\n",
      "(0.20747617506932522, 0.22370871989676799, 0.70303763125698004)\n",
      "iter:770, loss:1.13422252622\n",
      "(0.20745226008705142, 0.22370714511939829, 0.70303509323373437)\n",
      "iter:771, loss:1.13419449844\n",
      "(0.20778191264651868, 0.22364699064357893, 0.70285592665464591)\n",
      "iter:772, loss:1.13428482994\n",
      "(0.20776052658425362, 0.22364583290733134, 0.70285218920373405)\n",
      "iter:773, loss:1.1342585487\n",
      "(0.20773249159118606, 0.22364623175016948, 0.70285179768849537)\n",
      "iter:774, loss:1.13423052103\n",
      "(0.20770405500891026, 0.22364715658897083, 0.70285164449701021)\n",
      "iter:775, loss:1.13420285609\n",
      "(0.20767575471560715, 0.22364851855169288, 0.70285146220356431)\n",
      "iter:776, loss:1.13417573547\n",
      "(0.20764768753975882, 0.22365030137539044, 0.7028512024871898)\n",
      "iter:777, loss:1.1341491914\n",
      "(0.20761996384434656, 0.22365248637715618, 0.70285081014765538)\n",
      "iter:778, loss:1.13412326037\n",
      "(0.20759283155378325, 0.22365503159689376, 0.70285016118656118)\n",
      "iter:779, loss:1.13409802434\n",
      "(0.20756699164666967, 0.22365781842566737, 0.70284890504238173)\n",
      "iter:780, loss:1.13407371511\n",
      "(0.20754526826874373, 0.22366036901778724, 0.70284562941344741)\n",
      "iter:781, loss:1.1340512667\n",
      "(0.20754818466361483, 0.22365921028814228, 0.70283007175993406)\n",
      "iter:782, loss:1.13403746671\n",
      "(0.20753422572925981, 0.223661354491616, 0.70282298790865105)\n",
      "iter:783, loss:1.13401856813\n",
      "(0.20786588267339401, 0.22360547567917111, 0.70264325610701273)\n",
      "iter:784, loss:1.13411461446\n",
      "(0.20784157053642441, 0.22361018744150329, 0.70264141625842913)\n",
      "iter:785, loss:1.13409317424\n",
      "(0.20781395663197375, 0.22361592467947089, 0.70264124693951358)\n",
      "iter:786, loss:1.13407112825\n",
      "(0.20778630765641778, 0.22362212904533563, 0.70264113236120551)\n",
      "iter:787, loss:1.13404956906\n",
      "(0.20775881090693793, 0.22362876775342225, 0.70264098059472513)\n",
      "iter:788, loss:1.13402855926\n",
      "(0.20773153166241115, 0.22363582948114394, 0.7026407591192585)\n",
      "iter:789, loss:1.13400812026\n",
      "(0.20770455978348215, 0.22364329876588041, 0.70264042299117946)\n",
      "iter:790, loss:1.13398828154\n",
      "(0.20767808900211474, 0.22365114234703448, 0.70263987531386052)\n",
      "iter:791, loss:1.13396910666\n",
      "(0.20765262934576267, 0.22365927274131217, 0.70263886101760564)\n",
      "iter:792, loss:1.1339507631\n",
      "(0.20762999620060968, 0.22366737866847775, 0.7026364722559939)\n",
      "iter:793, loss:1.13393384713\n",
      "(0.20762106089366711, 0.2236735959949554, 0.7026272727120555)\n",
      "iter:794, loss:1.1339219296\n",
      "(0.20765682315950384, 0.22367260156672919, 0.70259576230318066)\n",
      "iter:795, loss:1.13392518703\n",
      "(0.20763721163935867, 0.22368154420346087, 0.7025919723099191)\n",
      "iter:796, loss:1.13391072815\n",
      "(0.20765280217338014, 0.2236848947844505, 0.70257061888681194)\n",
      "iter:797, loss:1.13390831584\n",
      "(0.20763066143313413, 0.22369517744430634, 0.70256816679915601)\n",
      "iter:798, loss:1.13389400568\n",
      "(0.2079515455664257, 0.22364693254826573, 0.70239435300085107)\n",
      "iter:799, loss:1.13399283112\n",
      "(0.20791454275377561, 0.22366046555851959, 0.7023994048210197)\n",
      "iter:800, loss:1.13397441313\n",
      "(0.20788650305338696, 0.22367303249996026, 0.70239999244437279)\n",
      "iter:801, loss:1.133959528\n",
      "(0.20785978925725646, 0.2236858444360332, 0.7023999538154686)\n",
      "iter:802, loss:1.13394558751\n",
      "(0.20783335081188431, 0.22369906970637141, 0.70239981625575276)\n",
      "iter:803, loss:1.13393223677\n",
      "(0.20780718675267185, 0.22371270716585273, 0.70239958041778361)\n",
      "iter:804, loss:1.13391947434\n",
      "(0.20778142543033792, 0.22372673427500389, 0.70239918211910035)\n",
      "iter:805, loss:1.13390734182\n",
      "(0.20775638159448054, 0.2237410961563164, 0.70239846394688399)\n",
      "iter:806, loss:1.1338959417\n",
      "(0.2077330100589381, 0.22375562656056303, 0.70239694840632105)\n",
      "iter:807, loss:1.13388558503\n",
      "(0.20771561714507208, 0.22376957594242666, 0.70239248202508009)\n",
      "iter:808, loss:1.13387767511\n",
      "(0.20773628709250669, 0.22377735896679696, 0.70236902207563334)\n",
      "iter:809, loss:1.13388266813\n",
      "(0.20771516549522412, 0.22379285864797793, 0.70236649300695142)\n",
      "iter:810, loss:1.13387451715\n",
      "(0.20795760931489063, 0.22376291712504984, 0.70223228446031272)\n",
      "iter:811, loss:1.1339528109\n",
      "(0.20790739152124874, 0.22378396928076488, 0.70224437838391518)\n",
      "iter:812, loss:1.13393573919\n",
      "(0.207879638021607, 0.22380188678083948, 0.70224526267807175)\n",
      "iter:813, loss:1.13392678748\n",
      "(0.20785410385132755, 0.22381990810742966, 0.70224507430789662)\n",
      "iter:814, loss:1.13391908627\n",
      "(0.20782918760261351, 0.22383828332157543, 0.70224461558562934)\n",
      "iter:815, loss:1.13391208651\n",
      "(0.20780531921229761, 0.22385693397658751, 0.70224367167812152)\n",
      "iter:816, loss:1.13390592487\n",
      "(0.20778432783180562, 0.22387553831865606, 0.70224132788531957)\n",
      "iter:817, loss:1.13390119404\n",
      "(0.2077768933074573, 0.22389221979241178, 0.70223224367787118)\n",
      "iter:818, loss:1.13390135678\n",
      "(0.2078050600428146, 0.22390309775236378, 0.70220539625312661)\n",
      "iter:819, loss:1.13391355405\n",
      "(0.20778613694087233, 0.22392268866911058, 0.70220212844549268)\n",
      "iter:820, loss:1.13391095406\n",
      "(0.20787994172445634, 0.22392289979153107, 0.70214254335771664)\n",
      "iter:821, loss:1.13394538487\n",
      "(0.20785695366249299, 0.22394398780289904, 0.70214137954462785)\n",
      "iter:822, loss:1.13394232101\n",
      "(0.20783386653082053, 0.22396564348490566, 0.70214029993924354)\n",
      "iter:823, loss:1.13393980995\n",
      "(0.20781791185203283, 0.22398650428343836, 0.70213569232870832)\n",
      "iter:824, loss:1.13394010846\n",
      "(0.20784608267351909, 0.22400002259942517, 0.70210906006525597)\n",
      "iter:825, loss:1.13395516534\n",
      "(0.20782617956587196, 0.22402246734268322, 0.70210649936069913)\n",
      "iter:826, loss:1.13395514627\n",
      "(0.20790760965536631, 0.22402743956064058, 0.70205331632351964)\n",
      "iter:827, loss:1.13398836554\n",
      "(0.20786068399388186, 0.22405505757211983, 0.70206434138280516)\n",
      "iter:828, loss:1.13398008295\n",
      "(0.20785609974693253, 0.22407607622850115, 0.70205422994404587)\n",
      "iter:829, loss:1.13398640592\n",
      "(0.20784997368454364, 0.22409786529691372, 0.70204492508808125)\n",
      "iter:830, loss:1.13399276407\n",
      "(0.20795679968688088, 0.22410004149699603, 0.70197919328028702)\n",
      "iter:831, loss:1.13403603446\n",
      "(0.20760894315526771, 0.22417762530003529, 0.70214093485324647)\n",
      "iter:832, loss:1.13392750331\n",
      "(0.20795078766641142, 0.22413846637675397, 0.70195769285178233)\n",
      "iter:833, loss:1.13404694689\n",
      "(0.20780119978054662, 0.22418345521339159, 0.70202028438607)\n",
      "iter:834, loss:1.13400493938\n",
      "(0.20808871685280694, 0.22415472398660935, 0.70186438853583244)\n",
      "iter:835, loss:1.13410782938\n",
      "(0.20769587589234981, 0.22424051786516341, 0.70204866742079031)\n",
      "iter:836, loss:1.13398506118\n",
      "(0.20798541322117881, 0.22421179762235066, 0.70189176124972297)\n",
      "iter:837, loss:1.13408897209\n",
      "(0.20770337597613897, 0.22428020801668286, 0.70202072663351511)\n",
      "iter:838, loss:1.13400431063\n",
      "(0.20802782077141002, 0.22424635401800558, 0.70184643981031436)\n",
      "iter:839, loss:1.1341206146\n",
      "(0.20769212253779568, 0.22432410176778889, 0.70200229633665068)\n",
      "iter:840, loss:1.13401852064\n",
      "(0.20800477801453496, 0.22429295810735264, 0.70183395593721709)\n",
      "iter:841, loss:1.13413169206\n",
      "(0.20769582413960422, 0.22436705241670618, 0.70197650465151973)\n",
      "iter:842, loss:1.13403938121\n",
      "(0.20801478709488166, 0.22433559683601234, 0.70180507617879018)\n",
      "iter:843, loss:1.13415546011\n",
      "(0.20769084940761648, 0.22441275446048234, 0.70195517956718778)\n",
      "iter:844, loss:1.13405878344\n",
      "(0.20800717649541167, 0.22438247250822571, 0.70178512705322771)\n",
      "iter:845, loss:1.13417477606\n",
      "(0.20769173167538665, 0.22445890014883874, 0.70193104676393236)\n",
      "iter:846, loss:1.13408167859\n",
      "(0.20800980168220895, 0.22442906721776132, 0.70176018563770981)\n",
      "iter:847, loss:1.13419905454\n",
      "(0.20768774171943449, 0.22450717140953241, 0.70190947654460634)\n",
      "iter:848, loss:1.13410438967\n",
      "(0.2080052860188436, 0.22447815499314469, 0.70173893731560832)\n",
      "iter:849, loss:1.13422237833\n",
      "(0.20768692280462195, 0.22455626087248809, 0.7018864429467806)\n",
      "iter:850, loss:1.13412962662\n",
      "(0.20800547842385242, 0.22452780930607494, 0.70171545951611058)\n",
      "iter:851, loss:1.13424874725\n",
      "(0.2076824058031107, 0.22460722642272446, 0.70186538427417389)\n",
      "iter:852, loss:1.1341550165\n",
      "(0.20800120702223474, 0.22457945633320794, 0.70169433675617099)\n",
      "iter:853, loss:1.13427500011\n",
      "(0.20768021312751936, 0.22465907023992654, 0.70184328589440748)\n",
      "iter:854, loss:1.13418256926\n",
      "(0.20800008449376525, 0.22463184806370431, 0.70167176369079698)\n",
      "iter:855, loss:1.13430369625\n",
      "(0.20767404966539735, 0.22471273442975104, 0.70182329887009109)\n",
      "iter:856, loss:1.13421008297\n",
      "(0.20799470968231829, 0.22468609447649346, 0.70165143982678302)\n",
      "iter:857, loss:1.13433224399\n",
      "(0.20767081273891974, 0.22476707553180578, 0.70180197025556357)\n",
      "iter:858, loss:1.13423985853\n",
      "(0.20799284664303261, 0.2247409267543371, 0.70162948377496093)\n",
      "iter:859, loss:1.13436325717\n",
      "(0.20766146536525598, 0.22482343259902088, 0.70178382369572478)\n",
      "iter:860, loss:1.13426872166\n",
      "(0.20798476083051468, 0.22479777586138017, 0.70161076147268275)\n",
      "iter:861, loss:1.13439329816\n",
      "(0.20765940795159074, 0.22487966347617847, 0.70176215004385012)\n",
      "iter:862, loss:1.13430122147\n",
      "(0.20798433739771935, 0.2248544557528061, 0.70158833093090078)\n",
      "iter:863, loss:1.13442712408\n",
      "(0.20764182639962486, 0.22493918740237395, 0.70174837032079018)\n",
      "iter:864, loss:1.13432938412\n",
      "(0.20796837517260056, 0.22491439110352363, 0.70157379031413647)\n",
      "iter:865, loss:1.13445655659\n",
      "(0.20765468689355557, 0.22499496057960752, 0.7017194702968319)\n",
      "iter:866, loss:1.13436911777\n",
      "(0.20798258734593097, 0.22497069601781783, 0.7015442850359791)\n",
      "iter:867, loss:1.1344975684\n",
      "(0.20759391506128416, 0.22506253127170819, 0.70172755741648807)\n",
      "iter:868, loss:1.13438400375\n",
      "(0.20792408307857738, 0.22503847777216868, 0.70155125516244032)\n",
      "iter:869, loss:1.13451381601\n",
      "(0.20772129927981955, 0.22510243222250242, 0.7016415674313865)\n",
      "iter:870, loss:1.13446529893\n",
      "(0.20804693294174537, 0.22508018828116999, 0.70146768581016816)\n",
      "iter:871, loss:1.13459480703\n",
      "(0.2073948130199445, 0.22520896971409191, 0.7017829853281069)\n",
      "iter:872, loss:1.13438676806\n",
      "(0.20772774936768756, 0.22518551901405798, 0.70160528324834548)\n",
      "iter:873, loss:1.13451855163\n",
      "(0.20802099991179657, 0.22516939713916773, 0.70144768105520416)\n",
      "iter:874, loss:1.13463807811\n",
      "(0.20741121839791377, 0.22529281571977569, 0.7017418655319031)\n",
      "iter:875, loss:1.13444589965\n",
      "(0.20774486159157513, 0.22527037819410831, 0.70156390937646906)\n",
      "iter:876, loss:1.13457914916\n",
      "(0.20801340150651443, 0.225259389095779, 0.70141875334503467)\n",
      "iter:877, loss:1.13469154395\n",
      "(0.20737012381168654, 0.22538814071348512, 0.701729804202195)\n",
      "iter:878, loss:1.13448806873\n",
      "(0.20770635538536733, 0.22536629944250289, 0.70155061568113297)\n",
      "iter:879, loss:1.13462327051\n",
      "(0.2080014732777983, 0.22535195464725619, 0.70139224496226482)\n",
      "iter:880, loss:1.13474567289\n",
      "(0.20737608658223966, 0.2254786696047274, 0.70169441313480641)\n",
      "iter:881, loss:1.13454916932\n",
      "(0.20771203166890381, 0.22545796762588743, 0.70151546159108846)\n",
      "iter:882, loss:1.13468546089\n",
      "(0.20799417790101174, 0.22544678665694731, 0.70136366474468259)\n",
      "iter:883, loss:1.1348046293\n",
      "(0.20734689958289376, 0.22557722564886676, 0.70167688164328246)\n",
      "iter:884, loss:1.13460100688\n",
      "(0.20768471249757087, 0.2255572465698934, 0.7014970665732978)\n",
      "iter:885, loss:1.13473902564\n",
      "(0.20798101886351544, 0.22554478725102955, 0.70133826576494018)\n",
      "iter:886, loss:1.13486407188\n",
      "(0.20734663238979223, 0.22567396688918137, 0.70164510626981513)\n",
      "iter:887, loss:1.13466570555\n",
      "(0.20768477828315665, 0.22565501478082131, 0.70146521389555094)\n",
      "iter:888, loss:1.13480500696\n",
      "(0.20797299616348924, 0.22564490151844613, 0.70131054338174958)\n",
      "iter:889, loss:1.13492844106\n",
      "(0.20732418321012036, 0.22577677917283184, 0.7016246913979316)\n",
      "iter:890, loss:1.13472565378\n",
      "(0.20766399669026084, 0.22575858517601191, 0.70144404035685382)\n",
      "iter:891, loss:1.13486662222\n",
      "(0.20796028255913324, 0.22574820019438568, 0.70128541370537956)\n",
      "iter:892, loss:1.13499389646\n",
      "(0.20731994094798484, 0.22587948125640375, 0.70159539959854655)\n",
      "iter:893, loss:1.1347948218\n",
      "(0.20766045001942054, 0.22586224183192241, 0.70141448732575529)\n",
      "iter:894, loss:1.13493717918\n",
      "(0.20795137569605612, 0.22585374653096821, 0.70125862523252502)\n",
      "iter:895, loss:1.13506374746\n",
      "(0.20730190598297915, 0.22598699408907211, 0.70157326388822094)\n",
      "iter:896, loss:1.13486216396\n",
      "(0.20764410693239638, 0.22597050720092593, 0.7013915838825715)\n",
      "iter:897, loss:1.13500619802\n",
      "(0.20793933774817702, 0.22596235072727594, 0.70123364847857506)\n",
      "iter:898, loss:1.13513533695\n",
      "(0.20729496265934219, 0.22609550908140244, 0.70154581598871535)\n",
      "iter:899, loss:1.13493628773\n",
      "(0.20763822738944715, 0.22607990157350027, 0.70136368907094071)\n",
      "iter:900, loss:1.13508181803\n",
      "(0.20792967268461734, 0.22607336942668527, 0.70120772970262635)\n",
      "iter:901, loss:1.13521077181\n",
      "(0.20727983338977959, 0.22620798570336667, 0.70152271441008396)\n",
      "iter:902, loss:1.1350105335\n",
      "(0.20762498265616777, 0.22619309317843192, 0.70133972551058155)\n",
      "iter:903, loss:1.13515780135\n",
      "(0.2079181757427776, 0.22618730453353592, 0.70118297249762118)\n",
      "iter:904, loss:1.13528845277\n",
      "(0.20727108783665485, 0.22632218734792914, 0.70149665937544869)\n",
      "iter:905, loss:1.13508993456\n",
      "(0.20761777562188546, 0.22630807893078098, 0.70131298533633801)\n",
      "iter:906, loss:1.13523883989\n",
      "(0.20790794109775712, 0.22630378097847959, 0.70115782859104026)\n",
      "iter:907, loss:1.13536955067\n",
      "(0.20725777552283242, 0.22643978974321471, 0.70147313713684656)\n",
      "iter:908, loss:1.1351707024\n",
      "(0.20760673613004091, 0.22642632105035743, 0.70128840841766726)\n",
      "iter:909, loss:1.1353214656\n",
      "(0.20789674920780241, 0.22642305712663721, 0.70113340874253316)\n",
      "iter:910, loss:1.13545321508\n",
      "(0.20724786393180147, 0.22655955902386685, 0.70144815608829725)\n",
      "iter:911, loss:1.13525557904\n",
      "(0.20759903447218298, 0.22654674259095062, 0.70126240622263214)\n",
      "iter:912, loss:1.13540818329\n",
      "(0.20788608434556688, 0.22654494327300256, 0.70110897009620798)\n",
      "iter:913, loss:1.13553999771\n",
      "(0.20723557647100929, 0.22668236920024359, 0.7014246102860594)\n",
      "iter:914, loss:1.13534255596\n",
      "(0.20758969418408213, 0.22667006247844379, 0.70123746965502864)\n",
      "iter:915, loss:1.13549722632\n",
      "(0.20787493404298574, 0.22666954017571769, 0.70108501973110848)\n",
      "iter:916, loss:1.13562949395\n",
      "(0.20722490637509322, 0.22680758520487118, 0.70140049949039474)\n",
      "iter:917, loss:1.13543299107\n",
      "(0.20758223717515512, 0.2267957369715243, 0.70121183630193684)\n",
      "iter:918, loss:1.13558981045\n",
      "(0.20786384799748711, 0.22679676135906629, 0.70106128251857314)\n",
      "iter:919, loss:1.13572189188\n",
      "(0.20721307144756343, 0.22693560966580409, 0.70137721768893313)\n",
      "iter:920, loss:1.1355258988\n",
      "(0.20757448668628861, 0.22692405345750999, 0.7011865960934448)\n",
      "iter:921, loss:1.13568513624\n",
      "(0.20785240556202819, 0.22692662107399594, 0.70103796956743514)\n",
      "iter:922, loss:1.1358169962\n",
      "(0.20720185286514922, 0.22706613217843757, 0.70135387307076391)\n",
      "iter:923, loss:1.13562185811\n",
      "(0.2075680560224937, 0.22705473381500299, 0.70116094212481217)\n",
      "iter:924, loss:1.13578373196\n",
      "(0.20784065094612406, 0.22705907737641456, 0.70101505892528637)\n",
      "iter:925, loss:1.13591478725\n",
      "(0.20719005659316828, 0.22719929261254146, 0.70133106421219449)\n",
      "iter:926, loss:1.13572041342\n",
      "(0.20756226758859755, 0.22718782103998358, 0.70113521432132064)\n",
      "iter:927, loss:1.13588530295\n",
      "(0.20782830214421125, 0.22719410767609666, 0.70099269241763151)\n",
      "iter:928, loss:1.13601510224\n",
      "(0.20717836630915915, 0.22733492561883162, 0.70130844933939185)\n",
      "iter:929, loss:1.13582174127\n",
      "(0.20755793745675652, 0.22732312539663324, 0.70110900516915509)\n",
      "iter:930, loss:1.13599006802\n",
      "(0.20781502492957069, 0.22733168916984559, 0.70097103769083646)\n",
      "iter:931, loss:1.13611775179\n",
      "(0.20716639269665121, 0.22747301620235438, 0.70128622415617936)\n",
      "iter:932, loss:1.13592563306\n",
      "(0.20755521126613583, 0.22746053283964385, 0.70108224291776189)\n",
      "iter:933, loss:1.13609798702\n",
      "(0.20780022319844185, 0.22747180921341839, 0.7009503936187319)\n",
      "iter:934, loss:1.13622242603\n",
      "(0.20715452317147037, 0.22761340652090878, 0.70126419537233897)\n",
      "iter:935, loss:1.13603212506\n",
      "(0.20755482461118366, 0.22759982229129375, 0.70105456051439041)\n",
      "iter:936, loss:1.13620920742\n",
      "(0.20778284162692467, 0.22761450076901563, 0.7009312882947375)\n",
      "iter:937, loss:1.13632863069\n",
      "(0.20714328727051934, 0.22775589576786284, 0.70124209804268334)\n",
      "iter:938, loss:1.13614128108\n",
      "(0.20755754799880688, 0.22774075247507697, 0.70102557276588107)\n",
      "iter:939, loss:1.13632387324\n",
      "(0.20776108641010504, 0.22775988521928034, 0.70091461814571954)\n",
      "iter:940, loss:1.13643558978\n",
      "(0.20713497844585099, 0.22790000232752394, 0.70121878201266574)\n",
      "iter:941, loss:1.13625376279\n",
      "(0.20756447462084651, 0.22788307654093332, 0.70099472980178146)\n",
      "iter:942, loss:1.13644228096\n",
      "(0.20773196392343143, 0.22790829925869574, 0.70090187597918385)\n",
      "iter:943, loss:1.13654213916\n",
      "(0.20713757509664008, 0.22804444382984573, 0.70119024359181703)\n",
      "iter:944, loss:1.13637226252\n",
      "(0.20757667731486965, 0.2280268303369998, 0.70096147995151348)\n",
      "iter:945, loss:1.1365649876\n",
      "(0.20769092294101668, 0.2280605980815742, 0.70089532144763278)\n",
      "iter:946, loss:1.13664684247\n",
      "(0.2071592690885925, 0.22818824068914081, 0.70115236211615062)\n",
      "iter:947, loss:1.13649987189\n",
      "(0.20759328315119277, 0.22817278630976948, 0.70092623231110651)\n",
      "iter:948, loss:1.13669230177\n",
      "(0.20752147993852613, 0.22823400753530004, 0.70095317342607955)\n",
      "iter:949, loss:1.1367086609\n",
      "(0.20783390464152215, 0.22824098710037943, 0.70078806448463415)\n",
      "iter:950, loss:1.13686295623\n",
      "(0.20708672793872548, 0.22840121765517304, 0.70115301007773845)\n",
      "iter:951, loss:1.13664095567\n",
      "(0.20763955081150576, 0.2283635478832097, 0.70086768699171953)\n",
      "iter:952, loss:1.13687078569\n",
      "(0.20748596580882067, 0.22843754107360248, 0.70093564182649393)\n",
      "iter:953, loss:1.13685914871\n",
      "(0.20778066016269209, 0.22844817683182647, 0.7007794751807106)\n",
      "iter:954, loss:1.13700831218\n",
      "(0.20705895631908428, 0.22860561867482876, 0.70113182485421621)\n",
      "iter:955, loss:1.13679639985\n",
      "(0.20763533920264265, 0.22856481370493104, 0.70083480638885109)\n",
      "iter:956, loss:1.1370349593\n",
      "(0.2074685500410321, 0.22864158825251485, 0.70090946805945353)\n",
      "iter:957, loss:1.13701960635\n",
      "(0.20776431967542802, 0.22865324438564977, 0.70075286123776326)\n",
      "iter:958, loss:1.1371704253\n",
      "(0.20705024868746827, 0.22881047925670661, 0.70110149379629816)\n",
      "iter:959, loss:1.13696222174\n",
      "(0.2076624878949562, 0.22876396192940512, 0.70078667816841012)\n",
      "iter:960, loss:1.13721312799\n",
      "(0.20734945613475403, 0.22886283599550833, 0.70093461062283025)\n",
      "iter:961, loss:1.13714690275\n",
      "(0.20769458807692673, 0.22886793131744884, 0.70075337608614596)\n",
      "iter:962, loss:1.13731589548\n",
      "(0.20713692588457083, 0.22900315970267934, 0.70102380320920021)\n",
      "iter:963, loss:1.1371638888\n",
      "(0.20769784908489983, 0.22896838626109886, 0.70073477490538139)\n",
      "iter:964, loss:1.13740101025\n",
      "(0.20726361034435448, 0.22908579363656503, 0.70094343655614022)\n",
      "iter:965, loss:1.13729284054\n",
      "(0.20765922471152989, 0.22908252286022629, 0.70073705688200505)\n",
      "iter:966, loss:1.13747880445\n",
      "(0.20721423026482019, 0.22920219940854564, 0.70095117315631084)\n",
      "iter:967, loss:1.13736760283\n",
      "(0.20767632326230143, 0.22918753438340086, 0.70071162485197869)\n",
      "iter:968, loss:1.1375754825\n",
      "(0.20721055363884772, 0.22931060549061574, 0.70093617939415132)\n",
      "iter:969, loss:1.13745733852\n",
      "(0.20768714403132255, 0.22929353589310864, 0.70068945248759373)\n",
      "iter:970, loss:1.13767013241\n",
      "(0.20718591443317971, 0.22942218849001506, 0.70093180172663017)\n",
      "iter:971, loss:1.13753990465\n",
      "(0.20773848175363335, 0.22939117390140781, 0.70064720408003311)\n",
      "iter:972, loss:1.13777685974\n",
      "(0.20716237205883928, 0.22953102182147594, 0.70092704770811043)\n",
      "iter:973, loss:1.13762044159\n",
      "(0.20771709202992217, 0.22949930608340582, 0.70064140905347427)\n",
      "iter:974, loss:1.13785780717\n",
      "(0.20717742470221151, 0.22963425027321241, 0.70090306824554727)\n",
      "iter:975, loss:1.13771474322\n",
      "(0.20773038544874048, 0.22960360227282633, 0.70061836950136425)\n",
      "iter:976, loss:1.13795235722\n",
      "(0.20715792109634326, 0.22974375781903983, 0.70089648187779063)\n",
      "iter:977, loss:1.13779816079\n",
      "(0.20773864777362075, 0.22970801306478356, 0.70059796191848489)\n",
      "iter:978, loss:1.13804462276\n",
      "(0.20716232273604043, 0.22984908488968583, 0.70087804138283749)\n",
      "iter:979, loss:1.13788944901\n",
      "(0.2077423248310567, 0.22981375262485351, 0.70057993852886113)\n",
      "iter:980, loss:1.13813601598\n",
      "(0.20715531710068849, 0.22995680163937809, 0.70086540565438149)\n",
      "iter:981, loss:1.13797752439\n",
      "(0.20775321341730854, 0.22991834133025801, 0.70055841767614124)\n",
      "iter:982, loss:1.13822997242\n",
      "(0.20715522881943685, 0.23006336494418222, 0.70084941120425304)\n",
      "iter:983, loss:1.13806800497\n",
      "(0.2077581904427464, 0.23002411013734383, 0.70053994668566666)\n",
      "iter:984, loss:1.13832224727\n",
      "(0.20715261290584872, 0.2301706433411258, 0.70083477827501151)\n",
      "iter:985, loss:1.13815803452\n",
      "(0.20776645839482791, 0.23012953114513512, 0.70051993018851932)\n",
      "iter:986, loss:1.13841591973\n",
      "(0.20715247093763797, 0.2302776782500871, 0.70081900462296232)\n",
      "iter:987, loss:1.13824915381\n",
      "(0.20777237762339532, 0.23023556684336835, 0.70050118178509679)\n",
      "iter:988, loss:1.13850912625\n",
      "(0.20715156172780058, 0.23038510758169092, 0.70080370953738091)\n",
      "iter:989, loss:1.13834037885\n",
      "(0.20777967295023633, 0.23034159371234836, 0.70048184103640321)\n",
      "iter:990, loss:1.1386031077\n",
      "(0.2071519976521915, 0.23049252632521197, 0.70078783555024549)\n",
      "iter:991, loss:1.13843235953\n",
      "(0.20778576880043551, 0.23044806230014436, 0.70046319209834762)\n",
      "iter:992, loss:1.1386970232\n",
      "(0.20715210338844822, 0.23060026523645238, 0.70077221924562461)\n",
      "iter:993, loss:1.13852458787\n",
      "(0.20779261090591475, 0.23055464103328976, 0.7004442628518539)\n",
      "iter:994, loss:1.13879151479\n",
      "(0.20715311999982608, 0.23070808647884281, 0.7007562389506542)\n",
      "iter:995, loss:1.13861744543\n",
      "(0.20779859252779934, 0.23066161901411047, 0.70042585394329659)\n",
      "iter:996, loss:1.13888606549\n",
      "(0.20715390445009024, 0.23081621873611297, 0.70074046520910238)\n",
      "iter:997, loss:1.1387105884\n",
      "(0.2078050905401391, 0.2307687605383956, 0.70040727732303854)\n",
      "iter:998, loss:1.1389811284\n",
      "(0.20715539829164997, 0.2309244832407803, 0.70072442619856257)\n",
      "iter:999, loss:1.13880430773\n",
      "(0.20781079792903329, 0.23087630624542263, 0.70038918410828088)\n",
      "\n",
      "The best result get at 809 iteration with loss: 1.133875\n",
      "Done!\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  9.99574259e-01,   9.99276857e-01,   9.99477174e-01,\n",
       "         9.99287927e-01,   9.99119298e-01,   9.98868980e-01,\n",
       "         9.97196687e-01,   9.98844081e-01,   9.98802928e-01,\n",
       "         9.99492602e-01,   9.98618967e-01,   9.99131605e-01,\n",
       "         9.97375634e-01,   9.98383896e-01,   9.98421555e-01,\n",
       "         9.99567532e-01,   9.99346989e-01,   9.98496243e-01,\n",
       "         9.99386654e-01,   9.99032303e-01,   9.99119541e-01,\n",
       "         9.98163729e-01,   9.99260346e-01,   9.99344587e-01,\n",
       "         9.98531176e-01,   9.99725458e-01,   9.99237336e-01,\n",
       "         9.99115399e-01,   9.99472103e-01,   9.98904084e-01,\n",
       "         9.98595914e-01,   9.96430742e-01,   9.99182949e-01,\n",
       "         9.98983665e-01,   9.99371488e-01,   9.98752404e-01,\n",
       "         9.99350143e-01,   9.98014974e-01,   9.98896762e-01,\n",
       "         9.98957143e-01,   9.99582789e-01,   9.99592088e-01,\n",
       "         9.98648468e-01,   9.99624666e-01,   9.99256151e-01,\n",
       "         9.98842785e-01,   9.99515645e-01,   9.99169240e-01,\n",
       "         9.98338005e-01,   9.98215545e-01,   9.98696985e-01,\n",
       "         9.99296848e-01,   9.99436389e-01,   9.97565405e-01,\n",
       "         9.98325303e-01,   9.98242596e-01,   9.97486200e-01,\n",
       "         9.98914677e-01,   9.98480024e-01,   9.99128403e-01,\n",
       "         9.99153655e-01,   9.98686211e-01,   9.98805176e-01,\n",
       "         9.98726570e-01,   9.98663512e-01,   9.99087249e-01,\n",
       "         9.98994742e-01,   9.98345910e-01,   9.97943478e-01,\n",
       "         9.98885624e-01,   9.98791118e-01,   9.99200730e-01,\n",
       "         9.98860277e-01,   9.99114782e-01,   9.99034318e-01,\n",
       "         9.99556548e-01,   9.99084447e-01,   9.99379575e-01,\n",
       "         9.99487026e-01,   9.99435450e-01,   9.99311561e-01,\n",
       "         9.99454828e-01,   9.99322221e-01,   9.99256461e-01,\n",
       "         9.99341948e-01,   9.99574575e-01,   9.98727578e-01,\n",
       "         9.98961481e-01,   9.99186523e-01,   9.98615645e-01,\n",
       "         9.99231465e-01,   9.98966482e-01,   9.99141697e-01,\n",
       "         9.99462282e-01,   9.99402186e-01,   9.98126284e-01,\n",
       "         9.99693606e-01,   9.99105845e-01,   9.99213195e-01,\n",
       "         9.99199784e-01,   7.36323931e-04,   9.68831157e-04,\n",
       "         1.38829035e-03,   6.92654289e-04,   6.50135363e-04,\n",
       "         1.20073636e-03,   6.18855448e-04,   2.10645913e-03,\n",
       "         1.70253999e-03,   1.51616506e-03,   6.24741747e-04,\n",
       "         7.40559759e-04,   6.78101134e-04,   3.89542902e-04,\n",
       "         1.13598597e-03,   1.25081083e-03,   7.45920808e-04,\n",
       "         1.22073653e-03,   8.52379060e-04,   4.47985286e-04,\n",
       "         7.53085496e-04,   5.98826295e-04,   7.29208422e-04,\n",
       "         1.17287713e-03,   9.97579422e-04,   9.73869767e-04,\n",
       "         1.06671250e-03,   4.34371117e-04,   1.85551299e-03,\n",
       "         7.43016184e-04,   1.04110131e-03,   5.51715403e-04,\n",
       "         5.74309471e-04,   5.28925796e-04,   1.31032956e-03,\n",
       "         7.62486681e-04,   8.50337923e-04,   5.35832840e-04,\n",
       "         1.14471788e-03,   7.58111644e-04,   1.54711592e-03,\n",
       "         9.35364674e-04,   2.30307493e-03,   6.73566714e-04,\n",
       "         1.54736407e-03,   9.87684543e-04,   1.56577882e-03,\n",
       "         1.74835226e-03,   1.39840028e-03,   8.25712693e-04,\n",
       "         6.98129863e-04,   1.04903023e-03,   7.90824755e-04,\n",
       "         8.88923350e-04,   7.30920055e-04,   7.76518048e-04,\n",
       "         5.82594620e-04,   9.05274166e-04,   1.07451782e-03,\n",
       "         9.98401817e-04,   8.44174445e-04,   1.84017487e-03,\n",
       "         1.02794965e-03,   7.54041040e-04,   1.70485826e-03,\n",
       "         1.44875526e-03,   8.51095852e-04,   7.96174305e-04,\n",
       "         7.01790172e-04,   7.90648874e-04,   1.15496294e-03,\n",
       "         1.12065071e-03,   1.94152148e-03,   1.48606865e-03,\n",
       "         1.34155967e-03,   9.94647450e-04,   9.24080710e-04,\n",
       "         1.16921481e-03,   5.71787534e-04,   1.23360253e-03,\n",
       "         5.04896495e-04,   4.69060127e-04,   9.63452551e-04,\n",
       "         1.42632420e-03,   1.42959326e-03,   5.58601232e-04,\n",
       "         1.18337637e-03,   9.27747769e-04,   1.45410397e-03,\n",
       "         1.35195866e-03,   1.31930703e-03,   1.42496247e-03,\n",
       "         3.70602410e-04,   6.11164882e-04,   9.47804257e-04,\n",
       "         8.20006923e-04,   7.00478600e-04,   1.26801134e-03,\n",
       "         8.38855536e-04,   5.41762281e-04])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predict = np.vectorize(mlr,excluded=['W','U'])\n",
    "pad = np.ones((200, 10 + 1))\n",
    "pad[:,:-1] = X\n",
    "X2 = pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (1,11) and (1,11) not aligned: 11 (dim 1) != 1 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-132-1e09542e24f7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mW\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight_W\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mU\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight_U\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/chris/anaconda2/lib/python2.7/site-packages/numpy/lib/function_base.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2732\u001b[0m             \u001b[0mvargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0m_n\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_n\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2733\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2734\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_vectorize_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2735\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2736\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_ufunc_and_otypes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/chris/anaconda2/lib/python2.7/site-packages/numpy/lib/function_base.pyc\u001b[0m in \u001b[0;36m_vectorize_call\u001b[1;34m(self, func, args)\u001b[0m\n\u001b[0;32m   2802\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2803\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2804\u001b[1;33m             \u001b[0mufunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0motypes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_ufunc_and_otypes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2805\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2806\u001b[0m             \u001b[1;31m# Convert args to object arrays first\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/chris/anaconda2/lib/python2.7/site-packages/numpy/lib/function_base.pyc\u001b[0m in \u001b[0;36m_get_ufunc_and_otypes\u001b[1;34m(self, func, args)\u001b[0m\n\u001b[0;32m   2762\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2763\u001b[0m             \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2764\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2765\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2766\u001b[0m             \u001b[1;31m# Performance note: profiling indicates that -- for simple\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/chris/anaconda2/lib/python2.7/site-packages/numpy/lib/function_base.pyc\u001b[0m in \u001b[0;36mfunc\u001b[1;34m(*vargs)\u001b[0m\n\u001b[0;32m   2727\u001b[0m                     \u001b[0mthe_args\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0m_i\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0m_n\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2728\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2729\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mthe_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2730\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2731\u001b[0m             \u001b[0mvargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0m_i\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_i\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minds\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-35-13a932addb69>\u001b[0m in \u001b[0;36mmlr\u001b[1;34m(W, U, x)\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[0meux\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mux\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[1;32mdel\u001b[0m \u001b[0mux\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meux\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (1,11) and (1,11) not aligned: 11 (dim 1) != 1 (dim 0)"
     ]
    }
   ],
   "source": [
    "predict(W = ls.weight_W, U = ls.weight_U, x = X2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'a' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-65-ea594c21b25d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-64-5130007d9dcf>\u001b[0m in \u001b[0;36mtest\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0ma\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-64-5130007d9dcf>\u001b[0m in \u001b[0;36madd\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0ma\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'a' referenced before assignment"
     ]
    }
   ],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = ls.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False], dtype=bool)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(y) > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
